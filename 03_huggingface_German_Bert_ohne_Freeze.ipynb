{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/BiancaStadl/Bachelorarbeit/blob/main/03_huggingface_German_Bert_ohne_Freeze.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BBsspqybXTK-"
      },
      "source": [
        "https://towardsdatascience.com/working-with-hugging-face-transformers-and-tf-2-0-89bf35e3555a\n",
        "\n",
        "\n",
        "Following is a general pipeline for any transformer model:\n",
        "Tokenizer definition ‚ÜíTokenization of Documents ‚ÜíModel Definition ‚ÜíModel Training ‚ÜíInference"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gYXyFyKAQjmg"
      },
      "source": [
        "https://colab.research.google.com/github/huggingface/notebooks/blob/master/transformers_doc/training.ipynb\n",
        "\n",
        "https://huggingface.co/transformers/ (get started)\n",
        "\n",
        "Sehr wichtig: https://huggingface.co/transformers/notebooks.html"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L7ifvIz0X2QH"
      },
      "source": [
        "Citation: Using GPU in colab and Tensorflow: https://colab.research.google.com/notebooks/gpu.ipynb#scrollTo=Y04m-jvKRDsJ"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NEx0JLGOX2my",
        "outputId": "e5b65f59-96f1-491a-b4cf-70a9a04944e3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found GPU at: /device:GPU:0\n"
          ]
        }
      ],
      "source": [
        "%tensorflow_version 2.x\n",
        "import tensorflow as tf\n",
        "device_name = tf.test.gpu_device_name()\n",
        "if device_name != '/device:GPU:0':\n",
        "  raise SystemError('GPU device not found')\n",
        "print('Found GPU at: {}'.format(device_name))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vj0g2dfIX4K-",
        "outputId": "159aa2d6-dc98-45fd-a443-2a57fed34ab7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time (s) to convolve 32x7x7x3 filter over random 100x100x100x3 images (batch x height x width x channel). Sum of ten runs.\n",
            "CPU (s):\n",
            "3.7813147960000606\n",
            "GPU (s):\n",
            "0.04718339300006846\n",
            "GPU speedup over CPU: 80x\n"
          ]
        }
      ],
      "source": [
        "%tensorflow_version 2.x\n",
        "import tensorflow as tf\n",
        "import timeit\n",
        "\n",
        "device_name = tf.test.gpu_device_name()\n",
        "if device_name != '/device:GPU:0':\n",
        "  print(\n",
        "      '\\n\\nThis error most likely means that this notebook is not '\n",
        "      'configured to use a GPU.  Change this in Notebook Settings via the '\n",
        "      'command palette (cmd/ctrl-shift-P) or the Edit menu.\\n\\n')\n",
        "  raise SystemError('GPU device not found')\n",
        "\n",
        "def cpu():\n",
        "  with tf.device('/cpu:0'):\n",
        "    random_image_cpu = tf.random.normal((100, 100, 100, 3))\n",
        "    net_cpu = tf.keras.layers.Conv2D(32, 7)(random_image_cpu)\n",
        "    return tf.math.reduce_sum(net_cpu)\n",
        "\n",
        "def gpu():\n",
        "  with tf.device('/device:GPU:0'):\n",
        "    random_image_gpu = tf.random.normal((100, 100, 100, 3))\n",
        "    net_gpu = tf.keras.layers.Conv2D(32, 7)(random_image_gpu)\n",
        "    return tf.math.reduce_sum(net_gpu)\n",
        "  \n",
        "# We run each op once to warm up; see: https://stackoverflow.com/a/45067900\n",
        "cpu()\n",
        "gpu()\n",
        "\n",
        "# Run the op several times.\n",
        "print('Time (s) to convolve 32x7x7x3 filter over random 100x100x100x3 images '\n",
        "      '(batch x height x width x channel). Sum of ten runs.')\n",
        "print('CPU (s):')\n",
        "cpu_time = timeit.timeit('cpu()', number=10, setup=\"from __main__ import cpu\")\n",
        "print(cpu_time)\n",
        "print('GPU (s):')\n",
        "gpu_time = timeit.timeit('gpu()', number=10, setup=\"from __main__ import gpu\")\n",
        "print(gpu_time)\n",
        "print('GPU speedup over CPU: {}x'.format(int(cpu_time/gpu_time)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "p3xfitNdliBI"
      },
      "outputs": [],
      "source": [
        "\n",
        "import os\n",
        "import re\n",
        "import shutil\n",
        "import string\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from keras import losses\n",
        "from tensorflow import keras \n",
        "from keras import optimizers \n",
        "from keras import metrics \n",
        "\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import losses\n",
        "from tensorflow.keras import preprocessing\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "Bq08Me5la_Cc"
      },
      "outputs": [],
      "source": [
        "max_length = 60"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "InRwhH-dt7P9"
      },
      "source": [
        "Next step is now to perform tokenization on documents. It can be performed either by encode() or encode_plus() method.\n",
        "https://towardsdatascience.com/working-with-hugging-face-transformers-and-tf-2-0-89bf35e3555a\n",
        "\n",
        "https://huggingface.co/bert-base-german-cased\n",
        "\n",
        "mit folgenden Paramter (laut doku)\n",
        "\n",
        "batch_size = 1024\n",
        "n_steps = 810_000\n",
        "max_seq_len = 128 (and 512 later)\n",
        "learning_rate = 1e-4\n",
        "lr_schedule = LinearWarmup\n",
        "num_warmup_steps = 10_000\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "I3XyiQsHNl0z"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "def tokenize(sentences, tokenizer):\n",
        "    input_ids, input_masks, input_segments = [],[],[]\n",
        "    for sentence in sentences:\n",
        "        inputs = tokenizer.encode_plus(sentence, add_special_tokens=True, max_length=60, pad_to_max_length=True, truncation=True,\n",
        "                                             return_attention_mask=True, return_token_type_ids=True)\n",
        "        input_ids.append(inputs['input_ids'])\n",
        "        input_masks.append(inputs['attention_mask'])\n",
        "        input_segments.append(inputs['token_type_ids'])        \n",
        "        \n",
        "    return np.asarray(input_ids, dtype='int32'), np.asarray(input_masks, dtype='int32'), np.asarray(input_segments, dtype='int32')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3mud88oeQ9UL",
        "outputId": "ed61eb12-26b2-47c5-a86c-7b4942da5a4b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.15.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.4.2)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.10.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.10.3)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.4.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.47)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.62.3)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (3.10.0.2)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.6)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.7.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.10.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.1.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_NYaByZROqzU",
        "outputId": "988e3815-11b4-437c-b7d9-b9cb135219d7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "All model checkpoint layers were used when initializing TFBertForMaskedLM.\n",
            "\n",
            "All the layers of TFBertForMaskedLM were initialized from the model checkpoint at bert-base-german-cased.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertForMaskedLM for predictions without further training.\n"
          ]
        }
      ],
      "source": [
        "#2.3.3 Fine-tuning a Pretrained transformer model, noch immer von https://towardsdatascience.com/working-with-hugging-face-transformers-and-tf-2-0-89bf35e3555a\n",
        "\n",
        "from transformers import AutoTokenizer, TFAutoModelForMaskedLM, AutoConfig, AutoModelForMaskedLM\n",
        "german_bert='bert-base-german-cased'\n",
        "\n",
        "\n",
        "  # Defining German bert tokenizer\n",
        "tokenizer = AutoTokenizer.from_pretrained(german_bert, max_length=60, pad_to_max_length=True,add_special_tokens=True)\n",
        "#add_special_tokens: ->  <cls>, <sep>,<unk>, etc w.r.t Pretrained model in use. It should be always kept True\n",
        "\n",
        "#https://huggingface.co/transformers/model_doc/auto.html#autoconfig\n",
        "# Download configuration from huggingface.co and cache.\n",
        "config = AutoConfig.from_pretrained('bert-base-german-cased', dropout=0.2, attention_dropout=0.2, num_labels=2)\n",
        "\n",
        "config.output_hidden_states = False\n",
        "\n",
        "German_model = TFAutoModelForMaskedLM.from_pretrained(german_bert, config=config)\n",
        "\n",
        "input_ids_in = tf.keras.layers.Input(shape=(60,), name='input_token', dtype='int32')\n",
        "input_attmasks_in = tf.keras.layers.Input(shape=(60,), name='attention_token', dtype='int32') \n",
        "token_type_ids_in = tf.keras.layers.Input(shape=(60,),name=\"token_type_ids\", dtype='int32')\n",
        "\n",
        "embedding_layer = German_model(input_ids=input_ids_in, attention_mask=input_attmasks_in, token_type_ids=token_type_ids_in)[0]\n",
        "X = tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(80, return_sequences=True, dropout=0.1))(embedding_layer)\n",
        "#X = tf.keras.layers.LSTM(100, return_sequences=True, dropout=0.3)(embedding_layer)\n",
        "X = tf.keras.layers.GlobalMaxPool1D()(X)\n",
        "X = tf.keras.layers.Dense(90, activation='relu')(X)\n",
        "X = tf.keras.layers.Dropout(0.2)(X)\n",
        "X = tf.keras.layers.Dense(1, activation='sigmoid')(X)\n",
        "model011902 = tf.keras.Model(inputs=[input_ids_in, input_attmasks_in,token_type_ids_in], outputs = X)\n",
        "\n",
        "\n",
        "# embedding_layer = German_model(input_ids=input_ids_in, attention_mask=input_attmasks_in)[0]\n",
        "# #X = tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(100, return_sequences=True, dropout=0.1, recurrent_dropout=0.1))(embedding_layer)\n",
        "# X = tf.keras.layers.LSTM(100, return_sequences=True, dropout=0.3)(embedding_layer)\n",
        "# X = tf.keras.layers.GlobalMaxPool1D()(X)\n",
        "# X = tf.keras.layers.Dense(190, activation='relu')(X)\n",
        "# X = tf.keras.layers.Dropout(0.2)(X)\n",
        "# X = tf.keras.layers.Dense(1, activation='sigmoid')(X)\n",
        "# model011902 = tf.keras.Model(inputs=[input_ids_in, input_attmasks_in], outputs = X)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mC3Ce-wNQINj",
        "outputId": "bf103f7d-6e00-49bc-8b60-82c2972a96d9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_token (InputLayer)       [(None, 60)]         0           []                               \n",
            "                                                                                                  \n",
            " attention_token (InputLayer)   [(None, 60)]         0           []                               \n",
            "                                                                                                  \n",
            " token_type_ids (InputLayer)    [(None, 60)]         0           []                               \n",
            "                                                                                                  \n",
            " tf_bert_for_masked_lm (TFBertF  TFMaskedLMOutput(lo  109112880  ['input_token[0][0]',            \n",
            " orMaskedLM)                    ss=None, logits=(No               'attention_token[0][0]',        \n",
            "                                ne, 60, 30000),                   'token_type_ids[0][0]']         \n",
            "                                 hidden_states=None                                               \n",
            "                                , attentions=None)                                                \n",
            "                                                                                                  \n",
            " bidirectional (Bidirectional)  (None, 60, 160)      19251840    ['tf_bert_for_masked_lm[0][0]']  \n",
            "                                                                                                  \n",
            " global_max_pooling1d (GlobalMa  (None, 160)         0           ['bidirectional[0][0]']          \n",
            " xPooling1D)                                                                                      \n",
            "                                                                                                  \n",
            " dense (Dense)                  (None, 90)           14490       ['global_max_pooling1d[0][0]']   \n",
            "                                                                                                  \n",
            " dropout_37 (Dropout)           (None, 90)           0           ['dense[0][0]']                  \n",
            "                                                                                                  \n",
            " dense_1 (Dense)                (None, 1)            91          ['dropout_37[0][0]']             \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 128,379,301\n",
            "Trainable params: 128,379,301\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model011902.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "G5qYC_xx_aTK"
      },
      "outputs": [],
      "source": [
        "import keras.backend as K\n",
        "\n",
        "def metrics_recall(data_true, data_pred):\n",
        "    true_positives = K.sum(K.round(K.clip(data_true*data_pred,0,1)))\n",
        "    possible_positives = K.sum(K.round(K.clip(data_true,0,1)))\n",
        "\n",
        "    recall = true_positives / (possible_positives+K.epsilon())\n",
        "    return recall\n",
        "\n",
        "\n",
        "def metrics_precision(data_true, data_pred):\n",
        "    true_positives = K.sum(K.round(K.clip(data_true*data_pred,0,1)))\n",
        "\n",
        "    positives_predicted = K.sum(K.round(K.clip(data_pred,0,1)))\n",
        "    precision = true_positives / (positives_predicted+K.epsilon())\n",
        "    return precision\n",
        "\n",
        "\n",
        "def metrics_f1(data_true, data_pred):\n",
        "    precision_data = metrics_precision(data_true, data_pred)\n",
        "    recall_data = metrics_recall(data_true, data_pred)\n",
        "    return 2*(precision_data*recall_data)/(precision_data+recall_data+K.epsilon())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "JVYBMvYSotTH"
      },
      "outputs": [],
      "source": [
        "url = \"https://github.com/uds-lsv/GermEval-2018-Data/archive/master.zip\"\n",
        "\n",
        "dataset = tf.keras.utils.get_file(\"GermEval-2018-Data-master.zip\", url, \n",
        "                                   extract=True, cache_dir='.',\n",
        "                                    cache_subdir='')\n",
        "\n",
        "dataset_dir = os.path.join(os.path.dirname(dataset), 'GermEval-2018-Data-master')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "cS14OUtfo34V"
      },
      "outputs": [],
      "source": [
        "#os.listdir(dataset_dir)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "2X429K6hpOVm"
      },
      "outputs": [],
      "source": [
        "training_file = os.path.join(dataset_dir, 'germeval2018.training.txt')\n",
        "#with open(training_file) as f:\n",
        " # print(f.read())\n",
        "\n",
        "#print()\n",
        "\n",
        "testing_file = os.path.join(dataset_dir, 'germeval2018.test.txt')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "iRqhP_Fx0cK3"
      },
      "outputs": [],
      "source": [
        "def remove_clutter(string):\n",
        "   string = re.sub(\"@[^\\s]+\",\" \",string)\n",
        "   string = re.sub(\"#[^\\s]+\",\" \", string)\n",
        "   string = re.sub(\"\\u00a9\",\" \", string)\n",
        "   string = re.sub(\"\\u00ae\",\" \", string)\n",
        "   string = re.sub(\"[\\u2000-\\u3300]\",\" \", string)\n",
        "   string = re.sub(\"\\ud83c[\\ud000-\\udfff]\",\" \", string)\n",
        "   string = re.sub(\"\\ud83d[\\ud000-\\udfff]\",\" \", string)\n",
        "   string = re.sub(\"\\ud83e[\\ud000-\\udfff]\",\" \", string)\n",
        "   string = re.sub(\"üòú\", \" \",string)\n",
        "   string = re.sub(\"üç´\", \" \",string)\n",
        "   string = re.sub(\"üòÅ\", \" \",string)\n",
        "   string = re.sub(\"üêñ\", \" \",string)\n",
        "   string = re.sub(\"üò°\", \" \",string)\n",
        "   string = re.sub(\"üòá\", \" \",string)\n",
        "   string = re.sub(\"üò¨\", \" \",string)\n",
        "   string = re.sub(\"üòÉ\", \" \",string)\n",
        "   string = re.sub(\"üòÇ\", \" \",string)\n",
        "   string = re.sub(\"üíô\", \" \",string)  \n",
        "   string = re.sub(\"üòõ\", \" \",string)\n",
        "   string = re.sub(\"üôè\", \" \",string)\n",
        "   string = re.sub(\"üëç\", \" \",string)\n",
        "   string = re.sub(\"üñï\", \" \",string)\n",
        "   string = re.sub(\"üòâ\", \" \",string)\n",
        "   string = re.sub(\"üí©\", \" \",string)\n",
        "   string = re.sub(\"ü§¢\", \" \",string)\n",
        "   string = re.sub(\"üëè\", \" \",string)\n",
        "   string = re.sub(\"üò®\", \" \",string)\n",
        "   string = re.sub(\"ü§£\", \" \",string)\n",
        "   string = re.sub(\"ü§°\", \" \",string)\n",
        "   string = re.sub(\"üòà\", \" \",string)\n",
        "   string = re.sub(\"üíÉüèΩ\", \" \",string)\n",
        "   string = re.sub(\"üëπ\", \" \",string)\n",
        "   string = re.sub(\"ü§ò\", \" \",string)\n",
        "   string = re.sub(\"üò±\", \" \",string)\n",
        "   string = re.sub(\"ü§î\", \" \",string) \n",
        "   string = re.sub(\"üåà\", \" \",string) \n",
        "   string = re.sub(\"üíï\", \" \",string) \n",
        "   string = re.sub(\"üë©‚Äç‚ù§Ô∏è‚Äçüë©\", \" \",string) \n",
        "   string = re.sub(\"üòç\", \" \",string) \n",
        "   string = re.sub(\"üëÜ\", \" \",string) \n",
        "   string = re.sub(\"üòñ\", \" \",string) \n",
        "   string = re.sub(\"üëá\", \" \",string) \n",
        "   string = re.sub(\"üî•\", \" \",string) \n",
        "   string = re.sub(\"üòò\", \" \",string) \n",
        "   string = re.sub(\"üéâ\", \" \",string) \n",
        "   string = re.sub(\"ü§¨\", \" \",string) \n",
        "   string = re.sub(\"üëä\", \" \",string)\n",
        "   string = re.sub(\"üá©üá™\", \" \",string)  \n",
        "   string = re.sub(\"üíî\", \" \",string)\n",
        "   string = re.sub(\"üôà\", \" \",string)\n",
        "   string = re.sub(\"ü§Ø\", \" \",string)\n",
        "   string = re.sub(\"üêü\", \" \",string)\n",
        "   string = re.sub(\"üõ∂\", \" \",string)\n",
        "   string = re.sub(\"üòä\", \" \",string)\n",
        "   string = re.sub(\"üòì\", \" \",string)\n",
        "   string = re.sub(\"üò≥\", \" \",string)\n",
        "   string = re.sub(\"üöÄ\", \" \",string)\n",
        "   string = re.sub(\"üëé\", \" \",string)\n",
        "   string = re.sub(\"üòé\", \" \",string)\n",
        "   string = re.sub(\"üê∏\", \" \",string)\n",
        "   string = re.sub(\"üìà\", \" \",string)\n",
        "   string = re.sub(\"üôÇ\", \" \",string)\n",
        "   string = re.sub(\"üòÖ\", \" \",string)\n",
        "   string = re.sub(\"üòÜ\", \" \",string)\n",
        "   string = re.sub(\"üôéüèø\", \" \",string)\n",
        "   string = re.sub(\"üëéüèΩ\", \" \",string)\n",
        "   string = re.sub(\"ü§≠\", \" \",string)\n",
        "   string = re.sub(\"üò§\", \" \",string)\n",
        "   string = re.sub(\"üòö\", \" \",string)\n",
        "   string = re.sub(\"üòä\", \" \",string)\n",
        "   string = re.sub(\"üò≤\", \" \",string)\n",
        "   string = re.sub(\"ü§Æ\", \" \",string)\n",
        "   string = re.sub(\"üôÑ\", \" \",string)\n",
        "   string = re.sub(\"ü§ë\", \" \",string)\n",
        "   string = re.sub(\"üéÖ\", \" \",string)\n",
        "   string = re.sub(\"üëã\", \" \",string)\n",
        "   string = re.sub(\"üí™\", \" \",string)\n",
        "   string = re.sub(\"üòÑ\", \" \",string)\n",
        "   string = re.sub(\"üßê\", \" \",string)\n",
        "   string = re.sub(\"üò†\", \" \",string)\n",
        "   string = re.sub(\"üéà\", \" \",string)\n",
        "   string = re.sub(\"üöÇ\", \" \",string)\n",
        "   string = re.sub(\"üòä\", \" \",string)\n",
        "   string = re.sub(\"üöá\", \" \",string)\n",
        "   string = re.sub(\"üöä\", \" \",string)\n",
        "   string = re.sub(\"ü§∑\", \" \",string)\n",
        "   string = re.sub(\"üò•\", \" \",string)\n",
        "   string = re.sub(\"üôÉ\", \" \",string)\n",
        "   string = re.sub(\"üî©\", \" \",string)\n",
        "   string = re.sub(\"üîß\", \" \",string)\n",
        "   string = re.sub(\"üî®\", \" \",string)\n",
        "   string = re.sub(\"üõ†\", \" \",string)\n",
        "   string = re.sub(\"üíì\", \" \",string)\n",
        "   string = re.sub(\"üí°\", \" \",string)\n",
        "   string = re.sub(\"üç∏\", \" \",string)\n",
        "   string = re.sub(\"ü•É\", \" \",string)\n",
        "   string = re.sub(\"ü•Ç\", \" \",string)\n",
        "   string = re.sub(\"üò∑\", \" \",string)\n",
        "   string = re.sub(\"ü§ê\", \" \",string)\n",
        "   string = re.sub(\"üåé\", \" \",string)\n",
        "   string = re.sub(\"üëë\", \" \",string)\n",
        "   string = re.sub(\"ü§õ\", \" \",string)\n",
        "   string = re.sub(\"üòÄ\", \" \",string)\n",
        "   string = re.sub(\"üõ§\", \" \",string)\n",
        "   string = re.sub(\"üéÑ\", \" \",string)\n",
        "   string = re.sub(\"üì¥\", \" \",string)\n",
        "   string = re.sub(\"üå≠\", \" \",string)\n",
        "   string = re.sub(\"ü§ï\", \" \",string)\n",
        "   string = re.sub(\"üò≠\", \" \",string)\n",
        "   string = re.sub(\"üçæ\", \" \",string)\n",
        "   string = re.sub(\"üçû\", \" \",string)\n",
        "   string = re.sub(\"ü§¶\", \" \",string)\n",
        "   string = re.sub(\"ü§Ø\", \" \",string)\n",
        "   string = re.sub(\"üïØÔ∏è\", \" \",string)\n",
        "\n",
        "   string = re.sub(\"OTHER|OFFENSE|ABUSE|INSULT\",\" \",string)\n",
        "   return string"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "5asMgo4LtnRg"
      },
      "outputs": [],
      "source": [
        "statementsForTraining = []\n",
        "sentimentsForTraining = []\n",
        "\n",
        "fileToRead = open(training_file, 'r')\n",
        "\n",
        "while True:\n",
        "  #next line in file\n",
        "  line = fileToRead.readline()\n",
        "\n",
        "  if line == \"\":\n",
        "   break\n",
        "\n",
        "  findSentiment = re.search(\"OTHER|OFFENSE\",line)\n",
        "\n",
        "  line = remove_clutter(line)\n",
        "      \n",
        "\n",
        "  statementsForTraining.append(line)\n",
        "\n",
        "  if findSentiment.group(0) == \"OTHER\":  \n",
        "    sentimentsForTraining.append(0)\n",
        "  else:\n",
        "    sentimentsForTraining.append(1)\n",
        "\n",
        "  if not line:\n",
        "    break\n",
        "\n",
        " #print(\"{}: {}\".format(count,line.strip()))\n",
        "  \n",
        " # print(sentiment.group(0))\n",
        " \n",
        "fileToRead.close()\n",
        "\n",
        "training_sentences = statementsForTraining\n",
        "training_labels = sentimentsForTraining\n",
        "\n",
        "#print(training_sentences[0:100])\n",
        "#print(training_labels[9])  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "VsqZPENb98gD"
      },
      "outputs": [],
      "source": [
        "\n",
        "statementsForTesting = []\n",
        "sentimentsForTesting = []\n",
        "\n",
        "fileToRead = open(testing_file, 'r')\n",
        "\n",
        "while True:\n",
        " \n",
        "  line = fileToRead.readline()\n",
        "\n",
        "  if line == \"\":\n",
        "   break\n",
        "\n",
        "  sent = re.search(\"OTHER|OFFENSE\",line)\n",
        "\n",
        "  line = remove_clutter(line)\n",
        "\n",
        "\n",
        "  statementsForTesting.append(line)\n",
        "  #print(len(line))\n",
        "\n",
        "  if sent.group(0) == \"OTHER\": \n",
        "    sentimentsForTesting.append(0)\n",
        "  else:\n",
        "    sentimentsForTesting.append(1)\n",
        "\n",
        "  if not line:\n",
        "    break\n",
        "\n",
        "\n",
        "fileToRead.close()\n",
        "\n",
        "\n",
        "testing_sentences = statementsForTesting\n",
        "testing_labels = sentimentsForTesting\n",
        "#print(len(testing_sentences))\n",
        "#print(testing_sentences)   \n",
        "#print(statementsForTesting)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "3XKTZ3dgItYe"
      },
      "outputs": [],
      "source": [
        "!pip install -q tf-models-official\n",
        "from official.nlp import optimization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vn7B2064ujon"
      },
      "source": [
        "[Linktext](https://stackoverflow.com/questions/38340311/what-is-the-difference-between-steps-and-epochs-in-tensorflow)\n",
        "What is train steps?\n",
        "Step: A training step means using one batch size of training data to train the model. Number of training steps per epoch: total_number_of_training_examples / batch_size . Total number of training steps: number_of_epochs x Number of training steps per epoch ."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3P-JYfZWQVh_",
        "outputId": "4298a8b3-ab08-470f-8c44-3f716719232e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:absl:using Adamw optimizer\n",
            "INFO:absl:gradient_clip_norm=1.000000\n"
          ]
        }
      ],
      "source": [
        "training_epochs = 3\n",
        "\n",
        "steps_per_epoch = 157\n",
        "num_train_steps = steps_per_epoch * training_epochs\n",
        "num_warmup_steps = int(0.1*num_train_steps)\n",
        "\n",
        "#init_lr = 3e-5\n",
        "#init_lr=2e-5\n",
        "#laut German bert docu:\n",
        "init_lr =1e-4 \n",
        "optimizer = optimization.create_optimizer(init_lr=init_lr,\n",
        "                                          num_train_steps=num_train_steps,\n",
        "                                          num_warmup_steps=num_warmup_steps,\n",
        "                                          optimizer_type='adamw')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "B-tWBjvUI_9x"
      },
      "outputs": [],
      "source": [
        "loss = tf.keras.losses.BinaryCrossentropy()\n",
        "metrics = tf.metrics.BinaryAccuracy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "D10-ZRr_QV6W"
      },
      "outputs": [],
      "source": [
        "model011902.compile(loss=loss, optimizer=optimizer ,metrics=[metrics,metrics_recall,metrics_precision,metrics_f1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cZWF9QIpOJga",
        "outputId": "fd6a9902-694f-4566-ae83-03df5ead971b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2232: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ]
        }
      ],
      "source": [
        "# Encode training set X\n",
        "X_train_ids, X_train_attention, X_segments = tokenize(training_sentences,tokenizer)\n",
        "\n",
        "# Encode test set\n",
        "Y_test_ids, Y_test_attention, Y_segments = tokenize(testing_sentences,tokenizer)\n",
        "#encding von https://towardsdatascience.com/hugging-face-transformers-fine-tuning-distilbert-for-binary-classification-tasks-490f1d192379"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qQhkO9_5SGs4"
      },
      "source": [
        "steps-per-epoch-Erkl√§rung...\n",
        "https://stackoverflow.com/questions/49922252/choosing-number-of-steps-per-epoch\n",
        "Traditionally, the steps per epoch is calculated as train_length // batch_size, since this will use all of the data points, one batch size worth at a time."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "RzowLK8xgHzQ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pIOKqYkGerVJ",
        "outputId": "4bcc98b2-10a1-4fe6-f764-ddb688cedbc9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3\n",
            "157/157 [==============================] - 217s 1s/step - loss: 0.5694 - binary_accuracy: 0.7099 - metrics_recall: 0.4530 - metrics_precision: 0.6051 - metrics_f1: 0.4666\n",
            "Epoch 2/3\n",
            "157/157 [==============================] - 190s 1s/step - loss: 0.4550 - binary_accuracy: 0.8044 - metrics_recall: 0.6385 - metrics_precision: 0.7601 - metrics_f1: 0.6681\n",
            "Epoch 3/3\n",
            "157/157 [==============================] - 190s 1s/step - loss: 0.3634 - binary_accuracy: 0.8581 - metrics_recall: 0.7696 - metrics_precision: 0.8042 - metrics_f1: 0.7763\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fa48f39ea90>"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ],
      "source": [
        "model011902.fit(\n",
        "    x = [X_train_ids, X_train_attention, X_segments],\n",
        "    y=np.array(training_labels),\n",
        "    epochs = 3,\n",
        "    batch_size = 32\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rfW_WcDlWsZv"
      },
      "source": [
        "https://deeplizard.com/learn/video/km7pxKy4UHU\n",
        "\n",
        "Quelle der def plot_confusion_matrix: https://scikit-learn.org/stable/auto_examples/model_selection/plot_confusion_matrix.html#sphx-glr-auto-examples-model-selection-plot-confusion-matrix-py "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "6KWbgX5NLk9r"
      },
      "outputs": [],
      "source": [
        "BERTGermanPredict = model011902.predict([Y_test_ids, Y_test_attention, Y_segments])\n",
        "BERT_pred_thresh = np.where(BERTGermanPredict >= 0.5, 1, 0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "rk4KctG_MJ20",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6776332c-f2a3-4522-93fa-069b0a6164e8"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0],\n",
              "       [1],\n",
              "       [0],\n",
              "       ...,\n",
              "       [1],\n",
              "       [0],\n",
              "       [0]])"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ],
      "source": [
        "BERT_pred_thresh"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "kOwlJFGrMKeM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "edc1dbe3-fc98-4e78-ccce-387f28ebae32"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.08314507],\n",
              "       [0.8998994 ],\n",
              "       [0.2481383 ],\n",
              "       ...,\n",
              "       [0.92840374],\n",
              "       [0.0866209 ],\n",
              "       [0.08487911]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ],
      "source": [
        "BERTGermanPredict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "TZjt-y0-WrPZ"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "import itertools\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "A5RUaFEcXmYc"
      },
      "outputs": [],
      "source": [
        "def plot_confusion_matrix(cm, classes,\n",
        "                        normalize=False,\n",
        "                        title='Confusion matrix',\n",
        "                        cmap=plt.cm.Blues):\n",
        "\n",
        "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
        "    plt.title(title)\n",
        "    plt.colorbar()\n",
        "    tick_marks = np.arange(len(classes))\n",
        "    plt.xticks(tick_marks, classes, rotation=45)\n",
        "    plt.yticks(tick_marks, classes)\n",
        "\n",
        "    if normalize:\n",
        "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
        "        print(\"Normalized confusion matrix\")\n",
        "    else:\n",
        "        print('Confusion matrix, without normalization')\n",
        "\n",
        "    print(cm)\n",
        "\n",
        "    thresh = cm.max() / 2.\n",
        "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
        "        plt.text(j, i, cm[i, j],\n",
        "            horizontalalignment=\"center\",\n",
        "            color=\"white\" if cm[i, j] > thresh else \"black\")\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.ylabel('True label')\n",
        "    plt.xlabel('Predicted label')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "4Mu7wle3Wr5S"
      },
      "outputs": [],
      "source": [
        "cm = confusion_matrix(y_true=testing_labels, y_pred=BERT_pred_thresh)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "QcIt6FU7Wr_q"
      },
      "outputs": [],
      "source": [
        "plot_labels = ['no hatespeech','hatespeech']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "X-K7cFJfWsGV",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "outputId": "c7cab902-e872-4a81-b5de-23f96bf41b2f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Confusion matrix, without normalization\n",
            "[[2034  296]\n",
            " [ 439  763]]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "plot_confusion_matrix(cm=cm, classes=plot_labels, title='German BERT, unfreezed')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "gE5mZvfmUyJF"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import accuracy_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "-3NPPARgU0Kt"
      },
      "outputs": [],
      "source": [
        "accuracy = accuracy_score(testing_labels, BERT_pred_thresh)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "EUt-18pmU0pA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d438d293-356a-4bce-ed21-a15aaa5bab55"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7919026047565119"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ],
      "source": [
        "accuracy"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "03 huggingface German Bert ohne Freeze.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}