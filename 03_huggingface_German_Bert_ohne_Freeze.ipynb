{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/BiancaStadl/Bachelorarbeit/blob/main/03_huggingface_German_Bert_ohne_Freeze.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BBsspqybXTK-"
      },
      "source": [
        "https://towardsdatascience.com/working-with-hugging-face-transformers-and-tf-2-0-89bf35e3555a\n",
        "\n",
        "\n",
        "Following is a general pipeline for any transformer model:\n",
        "Tokenizer definition ‚ÜíTokenization of Documents ‚ÜíModel Definition ‚ÜíModel Training ‚ÜíInference"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gYXyFyKAQjmg"
      },
      "source": [
        "https://colab.research.google.com/github/huggingface/notebooks/blob/master/transformers_doc/training.ipynb\n",
        "\n",
        "https://huggingface.co/transformers/ (get started)\n",
        "\n",
        "Sehr wichtig: https://huggingface.co/transformers/notebooks.html"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L7ifvIz0X2QH"
      },
      "source": [
        "Citation: Using GPU in colab and Tensorflow: https://colab.research.google.com/notebooks/gpu.ipynb#scrollTo=Y04m-jvKRDsJ"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NEx0JLGOX2my",
        "outputId": "dae04f60-ed0d-4f7c-b067-d286ab795adc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found GPU at: /device:GPU:0\n"
          ]
        }
      ],
      "source": [
        "%tensorflow_version 2.x\n",
        "import tensorflow as tf\n",
        "device_name = tf.test.gpu_device_name()\n",
        "if device_name != '/device:GPU:0':\n",
        "  raise SystemError('GPU device not found')\n",
        "print('Found GPU at: {}'.format(device_name))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vj0g2dfIX4K-",
        "outputId": "0f9bed6a-5267-4a25-b717-1d0601bfac64"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time (s) to convolve 32x7x7x3 filter over random 100x100x100x3 images (batch x height x width x channel). Sum of ten runs.\n",
            "CPU (s):\n",
            "2.8194359990000066\n",
            "GPU (s):\n",
            "0.036087952000116275\n",
            "GPU speedup over CPU: 78x\n"
          ]
        }
      ],
      "source": [
        "%tensorflow_version 2.x\n",
        "import tensorflow as tf\n",
        "import timeit\n",
        "\n",
        "device_name = tf.test.gpu_device_name()\n",
        "if device_name != '/device:GPU:0':\n",
        "  print(\n",
        "      '\\n\\nThis error most likely means that this notebook is not '\n",
        "      'configured to use a GPU.  Change this in Notebook Settings via the '\n",
        "      'command palette (cmd/ctrl-shift-P) or the Edit menu.\\n\\n')\n",
        "  raise SystemError('GPU device not found')\n",
        "\n",
        "def cpu():\n",
        "  with tf.device('/cpu:0'):\n",
        "    random_image_cpu = tf.random.normal((100, 100, 100, 3))\n",
        "    net_cpu = tf.keras.layers.Conv2D(32, 7)(random_image_cpu)\n",
        "    return tf.math.reduce_sum(net_cpu)\n",
        "\n",
        "def gpu():\n",
        "  with tf.device('/device:GPU:0'):\n",
        "    random_image_gpu = tf.random.normal((100, 100, 100, 3))\n",
        "    net_gpu = tf.keras.layers.Conv2D(32, 7)(random_image_gpu)\n",
        "    return tf.math.reduce_sum(net_gpu)\n",
        "  \n",
        "# We run each op once to warm up; see: https://stackoverflow.com/a/45067900\n",
        "cpu()\n",
        "gpu()\n",
        "\n",
        "# Run the op several times.\n",
        "print('Time (s) to convolve 32x7x7x3 filter over random 100x100x100x3 images '\n",
        "      '(batch x height x width x channel). Sum of ten runs.')\n",
        "print('CPU (s):')\n",
        "cpu_time = timeit.timeit('cpu()', number=10, setup=\"from __main__ import cpu\")\n",
        "print(cpu_time)\n",
        "print('GPU (s):')\n",
        "gpu_time = timeit.timeit('gpu()', number=10, setup=\"from __main__ import gpu\")\n",
        "print(gpu_time)\n",
        "print('GPU speedup over CPU: {}x'.format(int(cpu_time/gpu_time)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "p3xfitNdliBI"
      },
      "outputs": [],
      "source": [
        "\n",
        "import os\n",
        "import re\n",
        "import shutil\n",
        "import string\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from keras import losses\n",
        "from tensorflow import keras \n",
        "from keras import optimizers \n",
        "from keras import metrics \n",
        "\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import losses\n",
        "from tensorflow.keras import preprocessing\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "Bq08Me5la_Cc"
      },
      "outputs": [],
      "source": [
        "max_length = 60"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "InRwhH-dt7P9"
      },
      "source": [
        "Next step is now to perform tokenization on documents. It can be performed either by encode() or encode_plus() method.\n",
        "https://towardsdatascience.com/working-with-hugging-face-transformers-and-tf-2-0-89bf35e3555a\n",
        "\n",
        "https://huggingface.co/bert-base-german-cased\n",
        "\n",
        "mit folgenden Paramter (laut doku)\n",
        "\n",
        "batch_size = 1024\n",
        "n_steps = 810_000\n",
        "max_seq_len = 128 (and 512 later)\n",
        "learning_rate = 1e-4\n",
        "lr_schedule = LinearWarmup\n",
        "num_warmup_steps = 10_000\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "I3XyiQsHNl0z"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "def tokenize(sentences, tokenizer):\n",
        "    input_ids, input_masks, input_segments = [],[],[]\n",
        "    for sentence in sentences:\n",
        "        inputs = tokenizer.encode_plus(sentence, add_special_tokens=True, max_length=60, pad_to_max_length=True, truncation=True,\n",
        "                                             return_attention_mask=True, return_token_type_ids=True)\n",
        "        input_ids.append(inputs['input_ids'])\n",
        "        input_masks.append(inputs['attention_mask'])\n",
        "        input_segments.append(inputs['token_type_ids'])        \n",
        "        \n",
        "    return np.asarray(input_ids, dtype='int32'), np.asarray(input_masks, dtype='int32'), np.asarray(input_segments, dtype='int32')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3mud88oeQ9UL",
        "outputId": "2c66725f-bce7-4009-9178-8be26ef0c717"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.15.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.10.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.4.0)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.47)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.62.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.4.2)\n",
            "Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.10.3)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (3.10.0.2)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.6)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.7.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.10.8)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.1.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_NYaByZROqzU",
        "outputId": "3d200e39-83fb-417b-a1ed-ebfb274ef1bb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "All model checkpoint layers were used when initializing TFBertForMaskedLM.\n",
            "\n",
            "All the layers of TFBertForMaskedLM were initialized from the model checkpoint at bert-base-german-cased.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertForMaskedLM for predictions without further training.\n"
          ]
        }
      ],
      "source": [
        "#2.3.3 Fine-tuning a Pretrained transformer model, noch immer von https://towardsdatascience.com/working-with-hugging-face-transformers-and-tf-2-0-89bf35e3555a\n",
        "\n",
        "from transformers import AutoTokenizer, TFAutoModelForMaskedLM, AutoConfig, AutoModelForMaskedLM\n",
        "german_bert='bert-base-german-cased'\n",
        "\n",
        "\n",
        "  # Defining German bert tokenizer\n",
        "tokenizer = AutoTokenizer.from_pretrained(german_bert, max_length=60, pad_to_max_length=True,add_special_tokens=True)\n",
        "#add_special_tokens: ->  <cls>, <sep>,<unk>, etc w.r.t Pretrained model in use. It should be always kept True\n",
        "\n",
        "#https://huggingface.co/transformers/model_doc/auto.html#autoconfig\n",
        "# Download configuration from huggingface.co and cache.\n",
        "config = AutoConfig.from_pretrained('bert-base-german-cased', dropout=0.2, attention_dropout=0.2, num_labels=2)\n",
        "\n",
        "config.output_hidden_states = False\n",
        "\n",
        "German_model = TFAutoModelForMaskedLM.from_pretrained(german_bert, config=config)\n",
        "\n",
        "input_ids_in = tf.keras.layers.Input(shape=(60,), name='input_token', dtype='int32')\n",
        "input_attmasks_in = tf.keras.layers.Input(shape=(60,), name='attention_token', dtype='int32') \n",
        "token_type_ids_in = tf.keras.layers.Input(shape=(60,),name=\"token_type_ids\", dtype='int32')\n",
        "\n",
        "embedding_layer = German_model(input_ids=input_ids_in, attention_mask=input_attmasks_in, token_type_ids=token_type_ids_in)[0]\n",
        "#X = tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(100, return_sequences=True, dropout=0.1, recurrent_dropout=0.1))(embedding_layer)\n",
        "X = tf.keras.layers.LSTM(100, return_sequences=True, dropout=0.3)(embedding_layer)\n",
        "X = tf.keras.layers.GlobalMaxPool1D()(X)\n",
        "X = tf.keras.layers.Dense(190, activation='relu')(X)\n",
        "X = tf.keras.layers.Dropout(0.2)(X)\n",
        "X = tf.keras.layers.Dense(1, activation='sigmoid')(X)\n",
        "model180103 = tf.keras.Model(inputs=[input_ids_in, input_attmasks_in,token_type_ids_in], outputs = X)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mC3Ce-wNQINj",
        "outputId": "cc01809c-05e1-4252-b845-71d4e1ff2198"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_token (InputLayer)       [(None, 60)]         0           []                               \n",
            "                                                                                                  \n",
            " attention_token (InputLayer)   [(None, 60)]         0           []                               \n",
            "                                                                                                  \n",
            " token_type_ids (InputLayer)    [(None, 60)]         0           []                               \n",
            "                                                                                                  \n",
            " tf_bert_for_masked_lm (TFBertF  TFMaskedLMOutput(lo  109112880  ['input_token[0][0]',            \n",
            " orMaskedLM)                    ss=None, logits=(No               'attention_token[0][0]',        \n",
            "                                ne, 60, 30000),                   'token_type_ids[0][0]']         \n",
            "                                 hidden_states=None                                               \n",
            "                                , attentions=None)                                                \n",
            "                                                                                                  \n",
            " lstm (LSTM)                    (None, 60, 100)      12040400    ['tf_bert_for_masked_lm[0][0]']  \n",
            "                                                                                                  \n",
            " global_max_pooling1d (GlobalMa  (None, 100)         0           ['lstm[0][0]']                   \n",
            " xPooling1D)                                                                                      \n",
            "                                                                                                  \n",
            " dense (Dense)                  (None, 190)          19190       ['global_max_pooling1d[0][0]']   \n",
            "                                                                                                  \n",
            " dropout_37 (Dropout)           (None, 190)          0           ['dense[0][0]']                  \n",
            "                                                                                                  \n",
            " dense_1 (Dense)                (None, 1)            191         ['dropout_37[0][0]']             \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 121,172,661\n",
            "Trainable params: 121,172,661\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model180103.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "G5qYC_xx_aTK"
      },
      "outputs": [],
      "source": [
        "import keras.backend as K\n",
        "\n",
        "def metrics_recall(data_true, data_pred):\n",
        "    true_positives = K.sum(K.round(K.clip(data_true*data_pred,0,1)))\n",
        "    possible_positives = K.sum(K.round(K.clip(data_true,0,1)))\n",
        "\n",
        "    recall = true_positives / (possible_positives+K.epsilon())\n",
        "    return recall\n",
        "\n",
        "\n",
        "def metrics_precision(data_true, data_pred):\n",
        "    true_positives = K.sum(K.round(K.clip(data_true*data_pred,0,1)))\n",
        "\n",
        "    positives_predicted = K.sum(K.round(K.clip(data_pred,0,1)))\n",
        "    precision = true_positives / (positives_predicted+K.epsilon())\n",
        "    return precision\n",
        "\n",
        "\n",
        "def metrics_f1(data_true, data_pred):\n",
        "    precision_data = metrics_precision(data_true, data_pred)\n",
        "    recall_data = metrics_recall(data_true, data_pred)\n",
        "    return 2*(precision_data*recall_data)/(precision_data+recall_data+K.epsilon())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "JVYBMvYSotTH"
      },
      "outputs": [],
      "source": [
        "url = \"https://github.com/uds-lsv/GermEval-2018-Data/archive/master.zip\"\n",
        "\n",
        "dataset = tf.keras.utils.get_file(\"GermEval-2018-Data-master.zip\", url, \n",
        "                                   extract=True, cache_dir='.',\n",
        "                                    cache_subdir='')\n",
        "\n",
        "dataset_dir = os.path.join(os.path.dirname(dataset), 'GermEval-2018-Data-master')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "cS14OUtfo34V"
      },
      "outputs": [],
      "source": [
        "#os.listdir(dataset_dir)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "2X429K6hpOVm"
      },
      "outputs": [],
      "source": [
        "training_file = os.path.join(dataset_dir, 'germeval2018.training.txt')\n",
        "#with open(training_file) as f:\n",
        " # print(f.read())\n",
        "\n",
        "#print()\n",
        "\n",
        "testing_file = os.path.join(dataset_dir, 'germeval2018.test.txt')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "iRqhP_Fx0cK3"
      },
      "outputs": [],
      "source": [
        "def remove_clutter(string):\n",
        "   string = re.sub(\"@[^\\s]+\",\" \",string)\n",
        "   string = re.sub(\"#[^\\s]+\",\" \", string)\n",
        "   string = re.sub(\"\\u00a9\",\" \", string)\n",
        "   string = re.sub(\"\\u00ae\",\" \", string)\n",
        "   string = re.sub(\"[\\u2000-\\u3300]\",\" \", string)\n",
        "   string = re.sub(\"\\ud83c[\\ud000-\\udfff]\",\" \", string)\n",
        "   string = re.sub(\"\\ud83d[\\ud000-\\udfff]\",\" \", string)\n",
        "   string = re.sub(\"\\ud83e[\\ud000-\\udfff]\",\" \", string)\n",
        "   string = re.sub(\"üòú\", \" \",string)\n",
        "   string = re.sub(\"üç´\", \" \",string)\n",
        "   string = re.sub(\"üòÅ\", \" \",string)\n",
        "   string = re.sub(\"üêñ\", \" \",string)\n",
        "   string = re.sub(\"üò°\", \" \",string)\n",
        "   string = re.sub(\"üòá\", \" \",string)\n",
        "   string = re.sub(\"üò¨\", \" \",string)\n",
        "   string = re.sub(\"üòÉ\", \" \",string)\n",
        "   string = re.sub(\"üòÇ\", \" \",string)\n",
        "   string = re.sub(\"üíô\", \" \",string)  \n",
        "   string = re.sub(\"üòõ\", \" \",string)\n",
        "   string = re.sub(\"üôè\", \" \",string)\n",
        "   string = re.sub(\"üëç\", \" \",string)\n",
        "   string = re.sub(\"üñï\", \" \",string)\n",
        "   string = re.sub(\"üòâ\", \" \",string)\n",
        "   string = re.sub(\"üí©\", \" \",string)\n",
        "   string = re.sub(\"ü§¢\", \" \",string)\n",
        "   string = re.sub(\"üëè\", \" \",string)\n",
        "   string = re.sub(\"üò®\", \" \",string)\n",
        "   string = re.sub(\"ü§£\", \" \",string)\n",
        "   string = re.sub(\"ü§°\", \" \",string)\n",
        "   string = re.sub(\"üòà\", \" \",string)\n",
        "   string = re.sub(\"üíÉüèΩ\", \" \",string)\n",
        "   string = re.sub(\"üëπ\", \" \",string)\n",
        "   string = re.sub(\"ü§ò\", \" \",string)\n",
        "   string = re.sub(\"üò±\", \" \",string)\n",
        "   string = re.sub(\"ü§î\", \" \",string) \n",
        "   string = re.sub(\"üåà\", \" \",string) \n",
        "   string = re.sub(\"üíï\", \" \",string) \n",
        "   string = re.sub(\"üë©‚Äç‚ù§Ô∏è‚Äçüë©\", \" \",string) \n",
        "   string = re.sub(\"üòç\", \" \",string) \n",
        "   string = re.sub(\"üëÜ\", \" \",string) \n",
        "   string = re.sub(\"üòñ\", \" \",string) \n",
        "   string = re.sub(\"üëá\", \" \",string) \n",
        "   string = re.sub(\"üî•\", \" \",string) \n",
        "   string = re.sub(\"üòò\", \" \",string) \n",
        "   string = re.sub(\"üéâ\", \" \",string) \n",
        "   string = re.sub(\"ü§¨\", \" \",string) \n",
        "   string = re.sub(\"üëä\", \" \",string)\n",
        "   string = re.sub(\"üá©üá™\", \" \",string)  \n",
        "   string = re.sub(\"üíî\", \" \",string)\n",
        "   string = re.sub(\"üôà\", \" \",string)\n",
        "   string = re.sub(\"ü§Ø\", \" \",string)\n",
        "   string = re.sub(\"üêü\", \" \",string)\n",
        "   string = re.sub(\"üõ∂\", \" \",string)\n",
        "   string = re.sub(\"üòä\", \" \",string)\n",
        "   string = re.sub(\"üòì\", \" \",string)\n",
        "   string = re.sub(\"üò≥\", \" \",string)\n",
        "   string = re.sub(\"üöÄ\", \" \",string)\n",
        "   string = re.sub(\"üëé\", \" \",string)\n",
        "   string = re.sub(\"üòé\", \" \",string)\n",
        "   string = re.sub(\"üê∏\", \" \",string)\n",
        "   string = re.sub(\"üìà\", \" \",string)\n",
        "   string = re.sub(\"üôÇ\", \" \",string)\n",
        "   string = re.sub(\"üòÖ\", \" \",string)\n",
        "   string = re.sub(\"üòÜ\", \" \",string)\n",
        "   string = re.sub(\"üôéüèø\", \" \",string)\n",
        "   string = re.sub(\"üëéüèΩ\", \" \",string)\n",
        "   string = re.sub(\"ü§≠\", \" \",string)\n",
        "   string = re.sub(\"üò§\", \" \",string)\n",
        "   string = re.sub(\"üòö\", \" \",string)\n",
        "   string = re.sub(\"üòä\", \" \",string)\n",
        "   string = re.sub(\"üò≤\", \" \",string)\n",
        "   string = re.sub(\"ü§Æ\", \" \",string)\n",
        "   string = re.sub(\"üôÑ\", \" \",string)\n",
        "   string = re.sub(\"ü§ë\", \" \",string)\n",
        "   string = re.sub(\"üéÖ\", \" \",string)\n",
        "   string = re.sub(\"üëã\", \" \",string)\n",
        "   string = re.sub(\"üí™\", \" \",string)\n",
        "   string = re.sub(\"üòÑ\", \" \",string)\n",
        "   string = re.sub(\"üßê\", \" \",string)\n",
        "   string = re.sub(\"üò†\", \" \",string)\n",
        "   string = re.sub(\"üéà\", \" \",string)\n",
        "   string = re.sub(\"üöÇ\", \" \",string)\n",
        "   string = re.sub(\"üòä\", \" \",string)\n",
        "   string = re.sub(\"üöá\", \" \",string)\n",
        "   string = re.sub(\"üöä\", \" \",string)\n",
        "   string = re.sub(\"ü§∑\", \" \",string)\n",
        "   string = re.sub(\"üò•\", \" \",string)\n",
        "   string = re.sub(\"üôÉ\", \" \",string)\n",
        "   string = re.sub(\"üî©\", \" \",string)\n",
        "   string = re.sub(\"üîß\", \" \",string)\n",
        "   string = re.sub(\"üî®\", \" \",string)\n",
        "   string = re.sub(\"üõ†\", \" \",string)\n",
        "   string = re.sub(\"üíì\", \" \",string)\n",
        "   string = re.sub(\"üí°\", \" \",string)\n",
        "   string = re.sub(\"üç∏\", \" \",string)\n",
        "   string = re.sub(\"ü•É\", \" \",string)\n",
        "   string = re.sub(\"ü•Ç\", \" \",string)\n",
        "   string = re.sub(\"üò∑\", \" \",string)\n",
        "   string = re.sub(\"ü§ê\", \" \",string)\n",
        "   string = re.sub(\"üåé\", \" \",string)\n",
        "   string = re.sub(\"üëë\", \" \",string)\n",
        "   string = re.sub(\"ü§õ\", \" \",string)\n",
        "   string = re.sub(\"üòÄ\", \" \",string)\n",
        "   string = re.sub(\"üõ§\", \" \",string)\n",
        "   string = re.sub(\"üéÑ\", \" \",string)\n",
        "   string = re.sub(\"üì¥\", \" \",string)\n",
        "   string = re.sub(\"üå≠\", \" \",string)\n",
        "   string = re.sub(\"ü§ï\", \" \",string)\n",
        "   string = re.sub(\"üò≠\", \" \",string)\n",
        "   string = re.sub(\"üçæ\", \" \",string)\n",
        "   string = re.sub(\"üçû\", \" \",string)\n",
        "   string = re.sub(\"ü§¶\", \" \",string)\n",
        "   string = re.sub(\"ü§Ø\", \" \",string)\n",
        "   string = re.sub(\"üïØÔ∏è\", \" \",string)\n",
        "\n",
        "   string = re.sub(\"OTHER|OFFENSE|ABUSE|INSULT\",\" \",string)\n",
        "   return string"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "5asMgo4LtnRg"
      },
      "outputs": [],
      "source": [
        "statementsForTraining = []\n",
        "sentimentsForTraining = []\n",
        "\n",
        "fileToRead = open(training_file, 'r')\n",
        "\n",
        "while True:\n",
        "  #next line in file\n",
        "  line = fileToRead.readline()\n",
        "\n",
        "  if line == \"\":\n",
        "   break\n",
        "\n",
        "  findSentiment = re.search(\"OTHER|OFFENSE\",line)\n",
        "\n",
        "  line = remove_clutter(line)\n",
        "      \n",
        "\n",
        "  statementsForTraining.append(line)\n",
        "\n",
        "  if findSentiment.group(0) == \"OTHER\":  \n",
        "    sentimentsForTraining.append(0)\n",
        "  else:\n",
        "    sentimentsForTraining.append(1)\n",
        "\n",
        "  if not line:\n",
        "    break\n",
        "\n",
        " #print(\"{}: {}\".format(count,line.strip()))\n",
        "  \n",
        " # print(sentiment.group(0))\n",
        " \n",
        "fileToRead.close()\n",
        "\n",
        "training_sentences = statementsForTraining\n",
        "training_labels = sentimentsForTraining\n",
        "\n",
        "#print(training_sentences[0:100])\n",
        "#print(training_labels[9])  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "VsqZPENb98gD"
      },
      "outputs": [],
      "source": [
        "\n",
        "statementsForTesting = []\n",
        "sentimentsForTesting = []\n",
        "\n",
        "fileToRead = open(testing_file, 'r')\n",
        "\n",
        "while True:\n",
        " \n",
        "  line = fileToRead.readline()\n",
        "\n",
        "  if line == \"\":\n",
        "   break\n",
        "\n",
        "  sent = re.search(\"OTHER|OFFENSE\",line)\n",
        "\n",
        "  line = remove_clutter(line)\n",
        "\n",
        "\n",
        "  statementsForTesting.append(line)\n",
        "  #print(len(line))\n",
        "\n",
        "  if sent.group(0) == \"OTHER\": \n",
        "    sentimentsForTesting.append(0)\n",
        "  else:\n",
        "    sentimentsForTesting.append(1)\n",
        "\n",
        "  if not line:\n",
        "    break\n",
        "\n",
        "\n",
        "fileToRead.close()\n",
        "\n",
        "\n",
        "testing_sentences = statementsForTesting\n",
        "testing_labels = sentimentsForTesting\n",
        "#print(len(testing_sentences))\n",
        "#print(testing_sentences)   \n",
        "#print(statementsForTesting)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "3XKTZ3dgItYe"
      },
      "outputs": [],
      "source": [
        "!pip install -q tf-models-official\n",
        "from official.nlp import optimization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vn7B2064ujon"
      },
      "source": [
        "[Linktext](https://stackoverflow.com/questions/38340311/what-is-the-difference-between-steps-and-epochs-in-tensorflow)\n",
        "What is train steps?\n",
        "Step: A training step means using one batch size of training data to train the model. Number of training steps per epoch: total_number_of_training_examples / batch_size . Total number of training steps: number_of_epochs x Number of training steps per epoch ."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3P-JYfZWQVh_",
        "outputId": "4872c77e-47f6-4207-9c34-11b78e4ee329"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:absl:using Adamw optimizer\n",
            "INFO:absl:gradient_clip_norm=1.000000\n"
          ]
        }
      ],
      "source": [
        "training_epochs = 7\n",
        "\n",
        "steps_per_epoch = 157\n",
        "num_train_steps = steps_per_epoch * training_epochs\n",
        "num_warmup_steps = int(0.1*num_train_steps)\n",
        "\n",
        "#init_lr = 3e-5\n",
        "#init_lr=2e-5\n",
        "#laut German bert docu:\n",
        "init_lr =1e-4 \n",
        "optimizer = optimization.create_optimizer(init_lr=init_lr,\n",
        "                                          num_train_steps=num_train_steps,\n",
        "                                          num_warmup_steps=num_warmup_steps,\n",
        "                                          optimizer_type='adamw')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "B-tWBjvUI_9x"
      },
      "outputs": [],
      "source": [
        "loss = tf.keras.losses.BinaryCrossentropy()\n",
        "metrics = tf.metrics.BinaryAccuracy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "D10-ZRr_QV6W"
      },
      "outputs": [],
      "source": [
        "model180103.compile(loss=loss, optimizer=optimizer ,metrics=[metrics,metrics_recall,metrics_precision,metrics_f1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cZWF9QIpOJga",
        "outputId": "078287e6-83b5-4f28-c3f6-e626ad004597"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2232: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ]
        }
      ],
      "source": [
        "# Encode training set X\n",
        "X_train_ids, X_train_attention, X_segments = tokenize(training_sentences,tokenizer)\n",
        "\n",
        "# Encode test set\n",
        "Y_test_ids, Y_test_attention, Y_segments = tokenize(testing_sentences,tokenizer)\n",
        "#encding von https://towardsdatascience.com/hugging-face-transformers-fine-tuning-distilbert-for-binary-classification-tasks-490f1d192379"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qQhkO9_5SGs4"
      },
      "source": [
        "steps-per-epoch-Erkl√§rung...\n",
        "https://stackoverflow.com/questions/49922252/choosing-number-of-steps-per-epoch\n",
        "Traditionally, the steps per epoch is calculated as train_length // batch_size, since this will use all of the data points, one batch size worth at a time."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "RzowLK8xgHzQ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pIOKqYkGerVJ",
        "outputId": "94073343-86ab-45c5-ada8-5186d6122f4c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/7\n",
            "157/157 [==============================] - 100s 524ms/step - loss: 0.5779 - binary_accuracy: 0.7089 - metrics_recall: 0.3899 - metrics_precision: 0.5398 - metrics_f1: 0.4077\n",
            "Epoch 2/7\n",
            "157/157 [==============================] - 85s 540ms/step - loss: 0.5003 - binary_accuracy: 0.7710 - metrics_recall: 0.6505 - metrics_precision: 0.7030 - metrics_f1: 0.6413\n",
            "Epoch 3/7\n",
            "157/157 [==============================] - 86s 547ms/step - loss: 0.6405 - binary_accuracy: 0.6708 - metrics_recall: 0.0459 - metrics_precision: 0.0560 - metrics_f1: 0.0446\n",
            "Epoch 4/7\n",
            "157/157 [==============================] - 86s 547ms/step - loss: 0.6447 - binary_accuracy: 0.6624 - metrics_recall: 0.0000e+00 - metrics_precision: 0.0000e+00 - metrics_f1: 0.0000e+00\n",
            "Epoch 5/7\n",
            "157/157 [==============================] - 86s 547ms/step - loss: 0.6446 - binary_accuracy: 0.6624 - metrics_recall: 7.0771e-04 - metrics_precision: 0.0064 - metrics_f1: 0.0013\n",
            "Epoch 6/7\n",
            "157/157 [==============================] - 86s 547ms/step - loss: 0.6421 - binary_accuracy: 0.6628 - metrics_recall: 0.0000e+00 - metrics_precision: 0.0000e+00 - metrics_f1: 0.0000e+00\n",
            "Epoch 7/7\n",
            "157/157 [==============================] - 86s 547ms/step - loss: 0.6444 - binary_accuracy: 0.6626 - metrics_recall: 0.0000e+00 - metrics_precision: 0.0000e+00 - metrics_f1: 0.0000e+00\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f501c798950>"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ],
      "source": [
        "model180103.fit(\n",
        "    x = [X_train_ids, X_train_attention, X_segments],\n",
        "    y=np.array(training_labels),\n",
        "    epochs = 7,\n",
        "    batch_size = 32\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rfW_WcDlWsZv"
      },
      "source": [
        "https://deeplizard.com/learn/video/km7pxKy4UHU\n",
        "\n",
        "Quelle der def plot_confusion_matrix: https://scikit-learn.org/stable/auto_examples/model_selection/plot_confusion_matrix.html#sphx-glr-auto-examples-model-selection-plot-confusion-matrix-py "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "6KWbgX5NLk9r"
      },
      "outputs": [],
      "source": [
        "BERTGermanPredict = model180103.predict([Y_test_ids, Y_test_attention, Y_segments])\n",
        "BERT_pred_thresh = np.where(BERTGermanPredict >= 0.5, 1, 0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rk4KctG_MJ20",
        "outputId": "7177c01e-3e0e-4db3-d30a-9340af23f7f2"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0],\n",
              "       [0],\n",
              "       [0],\n",
              "       ...,\n",
              "       [0],\n",
              "       [0],\n",
              "       [0]])"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ],
      "source": [
        "BERT_pred_thresh"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kOwlJFGrMKeM",
        "outputId": "373304d2-ed92-4f1a-b42d-8affb1a58dbb"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.33495784],\n",
              "       [0.3349578 ],\n",
              "       [0.3349578 ],\n",
              "       ...,\n",
              "       [0.3349578 ],\n",
              "       [0.3349578 ],\n",
              "       [0.3349578 ]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ],
      "source": [
        "BERTGermanPredict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "TZjt-y0-WrPZ"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "import itertools\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "A5RUaFEcXmYc"
      },
      "outputs": [],
      "source": [
        "def plot_confusion_matrix(cm, classes,\n",
        "                        normalize=False,\n",
        "                        title='Confusion matrix',\n",
        "                        cmap=plt.cm.Blues):\n",
        "\n",
        "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
        "    plt.title(title)\n",
        "    plt.colorbar()\n",
        "    tick_marks = np.arange(len(classes))\n",
        "    plt.xticks(tick_marks, classes, rotation=45)\n",
        "    plt.yticks(tick_marks, classes)\n",
        "\n",
        "    if normalize:\n",
        "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
        "        print(\"Normalized confusion matrix\")\n",
        "    else:\n",
        "        print('Confusion matrix, without normalization')\n",
        "\n",
        "    print(cm)\n",
        "\n",
        "    thresh = cm.max() / 2.\n",
        "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
        "        plt.text(j, i, cm[i, j],\n",
        "            horizontalalignment=\"center\",\n",
        "            color=\"white\" if cm[i, j] > thresh else \"black\")\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.ylabel('True label')\n",
        "    plt.xlabel('Predicted label')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "4Mu7wle3Wr5S"
      },
      "outputs": [],
      "source": [
        "cm = confusion_matrix(y_true=testing_labels, y_pred=BERT_pred_thresh)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "QcIt6FU7Wr_q"
      },
      "outputs": [],
      "source": [
        "plot_labels = ['no hatespeech','hatespeech']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "X-K7cFJfWsGV",
        "outputId": "920ad6f9-ffe2-4348-d4b3-586165e1b444"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Confusion matrix, without normalization\n",
            "[[2330    0]\n",
            " [1202    0]]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "plot_confusion_matrix(cm=cm, classes=plot_labels, title='German BERT, unfreezed')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "gE5mZvfmUyJF"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import accuracy_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "-3NPPARgU0Kt"
      },
      "outputs": [],
      "source": [
        "accuracy = accuracy_score(testing_labels, BERT_pred_thresh)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EUt-18pmU0pA",
        "outputId": "53ab9117-b6cb-427d-be44-fccc6e0b1f46"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.659682899207248"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ],
      "source": [
        "accuracy"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "03 huggingface German Bert ohne Freeze.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}