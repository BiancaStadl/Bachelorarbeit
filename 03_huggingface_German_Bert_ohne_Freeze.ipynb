{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/BiancaStadl/Bachelorarbeit/blob/main/03_huggingface_German_Bert_ohne_Freeze.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BBsspqybXTK-"
      },
      "source": [
        "https://towardsdatascience.com/working-with-hugging-face-transformers-and-tf-2-0-89bf35e3555a\n",
        "\n",
        "\n",
        "Following is a general pipeline for any transformer model:\n",
        "Tokenizer definition ‚ÜíTokenization of Documents ‚ÜíModel Definition ‚ÜíModel Training ‚ÜíInference"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gYXyFyKAQjmg"
      },
      "source": [
        "https://colab.research.google.com/github/huggingface/notebooks/blob/master/transformers_doc/training.ipynb\n",
        "\n",
        "https://huggingface.co/transformers/ (get started)\n",
        "\n",
        "Sehr wichtig: https://huggingface.co/transformers/notebooks.html"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L7ifvIz0X2QH"
      },
      "source": [
        "Citation: Using GPU in colab and Tensorflow: https://colab.research.google.com/notebooks/gpu.ipynb#scrollTo=Y04m-jvKRDsJ"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NEx0JLGOX2my",
        "outputId": "aa01627b-e594-4118-b504-13bbc5a239f1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found GPU at: /device:GPU:0\n"
          ]
        }
      ],
      "source": [
        "%tensorflow_version 2.x\n",
        "import tensorflow as tf\n",
        "device_name = tf.test.gpu_device_name()\n",
        "if device_name != '/device:GPU:0':\n",
        "  raise SystemError('GPU device not found')\n",
        "print('Found GPU at: {}'.format(device_name))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vj0g2dfIX4K-",
        "outputId": "107e4abe-5718-4cd6-96d8-48eb4a9fd90e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time (s) to convolve 32x7x7x3 filter over random 100x100x100x3 images (batch x height x width x channel). Sum of ten runs.\n",
            "CPU (s):\n",
            "2.903627310000047\n",
            "GPU (s):\n",
            "0.036840249999841035\n",
            "GPU speedup over CPU: 78x\n"
          ]
        }
      ],
      "source": [
        "%tensorflow_version 2.x\n",
        "import tensorflow as tf\n",
        "import timeit\n",
        "\n",
        "device_name = tf.test.gpu_device_name()\n",
        "if device_name != '/device:GPU:0':\n",
        "  print(\n",
        "      '\\n\\nThis error most likely means that this notebook is not '\n",
        "      'configured to use a GPU.  Change this in Notebook Settings via the '\n",
        "      'command palette (cmd/ctrl-shift-P) or the Edit menu.\\n\\n')\n",
        "  raise SystemError('GPU device not found')\n",
        "\n",
        "def cpu():\n",
        "  with tf.device('/cpu:0'):\n",
        "    random_image_cpu = tf.random.normal((100, 100, 100, 3))\n",
        "    net_cpu = tf.keras.layers.Conv2D(32, 7)(random_image_cpu)\n",
        "    return tf.math.reduce_sum(net_cpu)\n",
        "\n",
        "def gpu():\n",
        "  with tf.device('/device:GPU:0'):\n",
        "    random_image_gpu = tf.random.normal((100, 100, 100, 3))\n",
        "    net_gpu = tf.keras.layers.Conv2D(32, 7)(random_image_gpu)\n",
        "    return tf.math.reduce_sum(net_gpu)\n",
        "  \n",
        "# We run each op once to warm up; see: https://stackoverflow.com/a/45067900\n",
        "cpu()\n",
        "gpu()\n",
        "\n",
        "# Run the op several times.\n",
        "print('Time (s) to convolve 32x7x7x3 filter over random 100x100x100x3 images '\n",
        "      '(batch x height x width x channel). Sum of ten runs.')\n",
        "print('CPU (s):')\n",
        "cpu_time = timeit.timeit('cpu()', number=10, setup=\"from __main__ import cpu\")\n",
        "print(cpu_time)\n",
        "print('GPU (s):')\n",
        "gpu_time = timeit.timeit('gpu()', number=10, setup=\"from __main__ import gpu\")\n",
        "print(gpu_time)\n",
        "print('GPU speedup over CPU: {}x'.format(int(cpu_time/gpu_time)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "p3xfitNdliBI"
      },
      "outputs": [],
      "source": [
        "\n",
        "import os\n",
        "import re\n",
        "import shutil\n",
        "import string\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from keras import losses\n",
        "from tensorflow import keras \n",
        "from keras import optimizers \n",
        "from keras import metrics \n",
        "\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import losses\n",
        "from tensorflow.keras import preprocessing\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "Bq08Me5la_Cc"
      },
      "outputs": [],
      "source": [
        "max_length = 60"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "InRwhH-dt7P9"
      },
      "source": [
        "Next step is now to perform tokenization on documents. It can be performed either by encode() or encode_plus() method.\n",
        "https://towardsdatascience.com/working-with-hugging-face-transformers-and-tf-2-0-89bf35e3555a\n",
        "\n",
        "https://huggingface.co/bert-base-german-cased\n",
        "\n",
        "mit folgenden Paramter (laut doku)\n",
        "\n",
        "batch_size = 1024\n",
        "n_steps = 810_000\n",
        "max_seq_len = 128 (and 512 later)\n",
        "learning_rate = 1e-4\n",
        "lr_schedule = LinearWarmup\n",
        "num_warmup_steps = 10_000\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "I3XyiQsHNl0z"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "def tokenize(sentences, tokenizer):\n",
        "    input_ids, input_masks, input_segments = [],[],[]\n",
        "    for sentence in sentences:\n",
        "        inputs = tokenizer.encode_plus(sentence, add_special_tokens=True, max_length=60, pad_to_max_length=True, truncation=True,\n",
        "                                             return_attention_mask=True, return_token_type_ids=True)\n",
        "        input_ids.append(inputs['input_ids'])\n",
        "        input_masks.append(inputs['attention_mask'])\n",
        "        input_segments.append(inputs['token_type_ids'])        \n",
        "        \n",
        "    return np.asarray(input_ids, dtype='int32'), np.asarray(input_masks, dtype='int32'), np.asarray(input_segments, dtype='int32')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3mud88oeQ9UL",
        "outputId": "4a0a6d60-5281-4c6d-a4d8-6d0a9d5d81e0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.15.0)\n",
            "Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.10.3)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.47)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.62.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.4.2)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.4.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.10.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (3.10.0.2)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.6)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.7.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.10.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.1.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_NYaByZROqzU",
        "outputId": "e3f31733-78bd-4161-c0be-00e89ac2b4c4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "All model checkpoint layers were used when initializing TFBertForMaskedLM.\n",
            "\n",
            "All the layers of TFBertForMaskedLM were initialized from the model checkpoint at bert-base-german-cased.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertForMaskedLM for predictions without further training.\n"
          ]
        }
      ],
      "source": [
        "#2.3.3 Fine-tuning a Pretrained transformer model, noch immer von https://towardsdatascience.com/working-with-hugging-face-transformers-and-tf-2-0-89bf35e3555a\n",
        "\n",
        "from transformers import AutoTokenizer, TFAutoModelForMaskedLM, AutoConfig, AutoModelForMaskedLM\n",
        "german_bert='bert-base-german-cased'\n",
        "\n",
        "\n",
        "  # Defining German bert tokenizer\n",
        "tokenizer = AutoTokenizer.from_pretrained(german_bert, max_length=60, pad_to_max_length=True,add_special_tokens=True)\n",
        "#add_special_tokens: ->  <cls>, <sep>,<unk>, etc w.r.t Pretrained model in use. It should be always kept True\n",
        "\n",
        "#https://huggingface.co/transformers/model_doc/auto.html#autoconfig\n",
        "# Download configuration from huggingface.co and cache.\n",
        "config = AutoConfig.from_pretrained('bert-base-german-cased', dropout=0.2, attention_dropout=0.2, num_labels=2)\n",
        "\n",
        "config.output_hidden_states = False\n",
        "\n",
        "German_model21 = TFAutoModelForMaskedLM.from_pretrained(german_bert, config=config)\n",
        "\n",
        "input_ids_in = tf.keras.layers.Input(shape=(60,), name='input_token', dtype='int32')\n",
        "input_attmasks_in = tf.keras.layers.Input(shape=(60,), name='attention_token', dtype='int32') \n",
        "token_type_ids_in = tf.keras.layers.Input(shape=(60,),name=\"token_type_ids\", dtype='int32')\n",
        "\n",
        "embedding_layer = German_model21(input_ids=input_ids_in, attention_mask=input_attmasks_in, token_type_ids=token_type_ids_in)[0]\n",
        "X = tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(50, return_sequences=True, dropout=0.3))(embedding_layer)\n",
        "#X = tf.keras.layers.LSTM(100, return_sequences=True, dropout=0.3)(embedding_layer)\n",
        "X = tf.keras.layers.GlobalMaxPool1D()(X)\n",
        "X = tf.keras.layers.Dense(70, activation='relu')(X)\n",
        "X = tf.keras.layers.Dropout(0.2)(X)\n",
        "X = tf.keras.layers.Dense(1, activation='sigmoid')(X)\n",
        "model01203 = tf.keras.Model(inputs=[input_ids_in, input_attmasks_in,token_type_ids_in], outputs = X)\n",
        "\n",
        "\n",
        "# embedding_layer = German_model20(input_ids=input_ids_in, attention_mask=input_attmasks_in)[0]\n",
        "# #X = tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(100, return_sequences=True, dropout=0.1, recurrent_dropout=0.1))(embedding_layer)\n",
        "# X = tf.keras.layers.LSTM(100, return_sequences=True, dropout=0.3)(embedding_layer)\n",
        "# X = tf.keras.layers.GlobalMaxPool1D()(X)\n",
        "# X = tf.keras.layers.Dense(190, activation='relu')(X)\n",
        "# X = tf.keras.layers.Dropout(0.2)(X)\n",
        "# X = tf.keras.layers.Dense(1, activation='sigmoid')(X)\n",
        "# model01203 = tf.keras.Model(inputs=[input_ids_in, input_attmasks_in], outputs = X)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mC3Ce-wNQINj",
        "outputId": "d897d08f-982b-42cb-d9e2-65391bea8434"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_token (InputLayer)       [(None, 60)]         0           []                               \n",
            "                                                                                                  \n",
            " attention_token (InputLayer)   [(None, 60)]         0           []                               \n",
            "                                                                                                  \n",
            " token_type_ids (InputLayer)    [(None, 60)]         0           []                               \n",
            "                                                                                                  \n",
            " tf_bert_for_masked_lm (TFBertF  TFMaskedLMOutput(lo  109112880  ['input_token[0][0]',            \n",
            " orMaskedLM)                    ss=None, logits=(No               'attention_token[0][0]',        \n",
            "                                ne, 60, 30000),                   'token_type_ids[0][0]']         \n",
            "                                 hidden_states=None                                               \n",
            "                                , attentions=None)                                                \n",
            "                                                                                                  \n",
            " bidirectional (Bidirectional)  (None, 60, 100)      12020400    ['tf_bert_for_masked_lm[0][0]']  \n",
            "                                                                                                  \n",
            " global_max_pooling1d (GlobalMa  (None, 100)         0           ['bidirectional[0][0]']          \n",
            " xPooling1D)                                                                                      \n",
            "                                                                                                  \n",
            " dense (Dense)                  (None, 70)           7070        ['global_max_pooling1d[0][0]']   \n",
            "                                                                                                  \n",
            " dropout_37 (Dropout)           (None, 70)           0           ['dense[0][0]']                  \n",
            "                                                                                                  \n",
            " dense_1 (Dense)                (None, 1)            71          ['dropout_37[0][0]']             \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 121,140,421\n",
            "Trainable params: 121,140,421\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model01203.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "G5qYC_xx_aTK"
      },
      "outputs": [],
      "source": [
        "import keras.backend as K\n",
        "\n",
        "def metrics_recall(data_true, data_pred):\n",
        "    true_positives = K.sum(K.round(K.clip(data_true*data_pred,0,1)))\n",
        "    possible_positives = K.sum(K.round(K.clip(data_true,0,1)))\n",
        "\n",
        "    recall = true_positives / (possible_positives+K.epsilon())\n",
        "    return recall\n",
        "\n",
        "\n",
        "def metrics_precision(data_true, data_pred):\n",
        "    true_positives = K.sum(K.round(K.clip(data_true*data_pred,0,1)))\n",
        "\n",
        "    positives_predicted = K.sum(K.round(K.clip(data_pred,0,1)))\n",
        "    precision = true_positives / (positives_predicted+K.epsilon())\n",
        "    return precision\n",
        "\n",
        "\n",
        "def metrics_f1(data_true, data_pred):\n",
        "    precision_data = metrics_precision(data_true, data_pred)\n",
        "    recall_data = metrics_recall(data_true, data_pred)\n",
        "    return 2*(precision_data*recall_data)/(precision_data+recall_data+K.epsilon())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "JVYBMvYSotTH"
      },
      "outputs": [],
      "source": [
        "url = \"https://github.com/uds-lsv/GermEval-2018-Data/archive/master.zip\"\n",
        "\n",
        "dataset = tf.keras.utils.get_file(\"GermEval-2018-Data-master.zip\", url, \n",
        "                                   extract=True, cache_dir='.',\n",
        "                                    cache_subdir='')\n",
        "\n",
        "dataset_dir = os.path.join(os.path.dirname(dataset), 'GermEval-2018-Data-master')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "cS14OUtfo34V"
      },
      "outputs": [],
      "source": [
        "#os.listdir(dataset_dir)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "2X429K6hpOVm"
      },
      "outputs": [],
      "source": [
        "training_file = os.path.join(dataset_dir, 'germeval2018.training.txt')\n",
        "#with open(training_file) as f:\n",
        " # print(f.read())\n",
        "\n",
        "#print()\n",
        "\n",
        "testing_file = os.path.join(dataset_dir, 'germeval2018.test.txt')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "iRqhP_Fx0cK3"
      },
      "outputs": [],
      "source": [
        "def remove_clutter(string):\n",
        "   string = re.sub(\"@[^\\s]+\",\" \",string)\n",
        "   string = re.sub(\"#[^\\s]+\",\" \", string)\n",
        "   string = re.sub(\"\\u00a9\",\" \", string)\n",
        "   string = re.sub(\"\\u00ae\",\" \", string)\n",
        "   string = re.sub(\"[\\u2000-\\u3300]\",\" \", string)\n",
        "   string = re.sub(\"\\ud83c[\\ud000-\\udfff]\",\" \", string)\n",
        "   string = re.sub(\"\\ud83d[\\ud000-\\udfff]\",\" \", string)\n",
        "   string = re.sub(\"\\ud83e[\\ud000-\\udfff]\",\" \", string)\n",
        "   string = re.sub(\"üòú\", \" \",string)\n",
        "   string = re.sub(\"üç´\", \" \",string)\n",
        "   string = re.sub(\"üòÅ\", \" \",string)\n",
        "   string = re.sub(\"üêñ\", \" \",string)\n",
        "   string = re.sub(\"üò°\", \" \",string)\n",
        "   string = re.sub(\"üòá\", \" \",string)\n",
        "   string = re.sub(\"üò¨\", \" \",string)\n",
        "   string = re.sub(\"üòÉ\", \" \",string)\n",
        "   string = re.sub(\"üòÇ\", \" \",string)\n",
        "   string = re.sub(\"üíô\", \" \",string)  \n",
        "   string = re.sub(\"üòõ\", \" \",string)\n",
        "   string = re.sub(\"üôè\", \" \",string)\n",
        "   string = re.sub(\"üëç\", \" \",string)\n",
        "   string = re.sub(\"üñï\", \" \",string)\n",
        "   string = re.sub(\"üòâ\", \" \",string)\n",
        "   string = re.sub(\"üí©\", \" \",string)\n",
        "   string = re.sub(\"ü§¢\", \" \",string)\n",
        "   string = re.sub(\"üëè\", \" \",string)\n",
        "   string = re.sub(\"üò®\", \" \",string)\n",
        "   string = re.sub(\"ü§£\", \" \",string)\n",
        "   string = re.sub(\"ü§°\", \" \",string)\n",
        "   string = re.sub(\"üòà\", \" \",string)\n",
        "   string = re.sub(\"üíÉüèΩ\", \" \",string)\n",
        "   string = re.sub(\"üëπ\", \" \",string)\n",
        "   string = re.sub(\"ü§ò\", \" \",string)\n",
        "   string = re.sub(\"üò±\", \" \",string)\n",
        "   string = re.sub(\"ü§î\", \" \",string) \n",
        "   string = re.sub(\"üåà\", \" \",string) \n",
        "   string = re.sub(\"üíï\", \" \",string) \n",
        "   string = re.sub(\"üë©‚Äç‚ù§Ô∏è‚Äçüë©\", \" \",string) \n",
        "   string = re.sub(\"üòç\", \" \",string) \n",
        "   string = re.sub(\"üëÜ\", \" \",string) \n",
        "   string = re.sub(\"üòñ\", \" \",string) \n",
        "   string = re.sub(\"üëá\", \" \",string) \n",
        "   string = re.sub(\"üî•\", \" \",string) \n",
        "   string = re.sub(\"üòò\", \" \",string) \n",
        "   string = re.sub(\"üéâ\", \" \",string) \n",
        "   string = re.sub(\"ü§¨\", \" \",string) \n",
        "   string = re.sub(\"üëä\", \" \",string)\n",
        "   string = re.sub(\"üá©üá™\", \" \",string)  \n",
        "   string = re.sub(\"üíî\", \" \",string)\n",
        "   string = re.sub(\"üôà\", \" \",string)\n",
        "   string = re.sub(\"ü§Ø\", \" \",string)\n",
        "   string = re.sub(\"üêü\", \" \",string)\n",
        "   string = re.sub(\"üõ∂\", \" \",string)\n",
        "   string = re.sub(\"üòä\", \" \",string)\n",
        "   string = re.sub(\"üòì\", \" \",string)\n",
        "   string = re.sub(\"üò≥\", \" \",string)\n",
        "   string = re.sub(\"üöÄ\", \" \",string)\n",
        "   string = re.sub(\"üëé\", \" \",string)\n",
        "   string = re.sub(\"üòé\", \" \",string)\n",
        "   string = re.sub(\"üê∏\", \" \",string)\n",
        "   string = re.sub(\"üìà\", \" \",string)\n",
        "   string = re.sub(\"üôÇ\", \" \",string)\n",
        "   string = re.sub(\"üòÖ\", \" \",string)\n",
        "   string = re.sub(\"üòÜ\", \" \",string)\n",
        "   string = re.sub(\"üôéüèø\", \" \",string)\n",
        "   string = re.sub(\"üëéüèΩ\", \" \",string)\n",
        "   string = re.sub(\"ü§≠\", \" \",string)\n",
        "   string = re.sub(\"üò§\", \" \",string)\n",
        "   string = re.sub(\"üòö\", \" \",string)\n",
        "   string = re.sub(\"üòä\", \" \",string)\n",
        "   string = re.sub(\"üò≤\", \" \",string)\n",
        "   string = re.sub(\"ü§Æ\", \" \",string)\n",
        "   string = re.sub(\"üôÑ\", \" \",string)\n",
        "   string = re.sub(\"ü§ë\", \" \",string)\n",
        "   string = re.sub(\"üéÖ\", \" \",string)\n",
        "   string = re.sub(\"üëã\", \" \",string)\n",
        "   string = re.sub(\"üí™\", \" \",string)\n",
        "   string = re.sub(\"üòÑ\", \" \",string)\n",
        "   string = re.sub(\"üßê\", \" \",string)\n",
        "   string = re.sub(\"üò†\", \" \",string)\n",
        "   string = re.sub(\"üéà\", \" \",string)\n",
        "   string = re.sub(\"üöÇ\", \" \",string)\n",
        "   string = re.sub(\"üòä\", \" \",string)\n",
        "   string = re.sub(\"üöá\", \" \",string)\n",
        "   string = re.sub(\"üöä\", \" \",string)\n",
        "   string = re.sub(\"ü§∑\", \" \",string)\n",
        "   string = re.sub(\"üò•\", \" \",string)\n",
        "   string = re.sub(\"üôÉ\", \" \",string)\n",
        "   string = re.sub(\"üî©\", \" \",string)\n",
        "   string = re.sub(\"üîß\", \" \",string)\n",
        "   string = re.sub(\"üî®\", \" \",string)\n",
        "   string = re.sub(\"üõ†\", \" \",string)\n",
        "   string = re.sub(\"üíì\", \" \",string)\n",
        "   string = re.sub(\"üí°\", \" \",string)\n",
        "   string = re.sub(\"üç∏\", \" \",string)\n",
        "   string = re.sub(\"ü•É\", \" \",string)\n",
        "   string = re.sub(\"ü•Ç\", \" \",string)\n",
        "   string = re.sub(\"üò∑\", \" \",string)\n",
        "   string = re.sub(\"ü§ê\", \" \",string)\n",
        "   string = re.sub(\"üåé\", \" \",string)\n",
        "   string = re.sub(\"üëë\", \" \",string)\n",
        "   string = re.sub(\"ü§õ\", \" \",string)\n",
        "   string = re.sub(\"üòÄ\", \" \",string)\n",
        "   string = re.sub(\"üõ§\", \" \",string)\n",
        "   string = re.sub(\"üéÑ\", \" \",string)\n",
        "   string = re.sub(\"üì¥\", \" \",string)\n",
        "   string = re.sub(\"üå≠\", \" \",string)\n",
        "   string = re.sub(\"ü§ï\", \" \",string)\n",
        "   string = re.sub(\"üò≠\", \" \",string)\n",
        "   string = re.sub(\"üçæ\", \" \",string)\n",
        "   string = re.sub(\"üçû\", \" \",string)\n",
        "   string = re.sub(\"ü§¶\", \" \",string)\n",
        "   string = re.sub(\"ü§Ø\", \" \",string)\n",
        "   string = re.sub(\"üïØÔ∏è\", \" \",string)\n",
        "\n",
        "   string = re.sub(\"OTHER|OFFENSE|ABUSE|INSULT\",\" \",string)\n",
        "   return string"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "5asMgo4LtnRg"
      },
      "outputs": [],
      "source": [
        "statementsForTraining = []\n",
        "sentimentsForTraining = []\n",
        "\n",
        "fileToRead = open(training_file, 'r')\n",
        "\n",
        "while True:\n",
        "  #next line in file\n",
        "  line = fileToRead.readline()\n",
        "\n",
        "  if line == \"\":\n",
        "   break\n",
        "\n",
        "  findSentiment = re.search(\"OTHER|OFFENSE\",line)\n",
        "\n",
        "  line = remove_clutter(line)\n",
        "      \n",
        "\n",
        "  statementsForTraining.append(line)\n",
        "\n",
        "  if findSentiment.group(0) == \"OTHER\":  \n",
        "    sentimentsForTraining.append(0)\n",
        "  else:\n",
        "    sentimentsForTraining.append(1)\n",
        "\n",
        "  if not line:\n",
        "    break\n",
        "\n",
        " #print(\"{}: {}\".format(count,line.strip()))\n",
        "  \n",
        " # print(sentiment.group(0))\n",
        " \n",
        "fileToRead.close()\n",
        "\n",
        "training_sentences = statementsForTraining\n",
        "training_labels = sentimentsForTraining\n",
        "\n",
        "#print(training_sentences[0:100])\n",
        "#print(training_labels[9])  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "VsqZPENb98gD"
      },
      "outputs": [],
      "source": [
        "\n",
        "statementsForTesting = []\n",
        "sentimentsForTesting = []\n",
        "\n",
        "fileToRead = open(testing_file, 'r')\n",
        "\n",
        "while True:\n",
        " \n",
        "  line = fileToRead.readline()\n",
        "\n",
        "  if line == \"\":\n",
        "   break\n",
        "\n",
        "  sent = re.search(\"OTHER|OFFENSE\",line)\n",
        "\n",
        "  line = remove_clutter(line)\n",
        "\n",
        "\n",
        "  statementsForTesting.append(line)\n",
        "  #print(len(line))\n",
        "\n",
        "  if sent.group(0) == \"OTHER\": \n",
        "    sentimentsForTesting.append(0)\n",
        "  else:\n",
        "    sentimentsForTesting.append(1)\n",
        "\n",
        "  if not line:\n",
        "    break\n",
        "\n",
        "\n",
        "fileToRead.close()\n",
        "\n",
        "\n",
        "testing_sentences = statementsForTesting\n",
        "testing_labels = sentimentsForTesting\n",
        "#print(len(testing_sentences))\n",
        "#print(testing_sentences)   \n",
        "#print(statementsForTesting)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "3XKTZ3dgItYe"
      },
      "outputs": [],
      "source": [
        "!pip install -q tf-models-official\n",
        "from official.nlp import optimization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vn7B2064ujon"
      },
      "source": [
        "[Linktext](https://stackoverflow.com/questions/38340311/what-is-the-difference-between-steps-and-epochs-in-tensorflow)\n",
        "What is train steps?\n",
        "Step: A training step means using one batch size of training data to train the model. Number of training steps per epoch: total_number_of_training_examples / batch_size . Total number of training steps: number_of_epochs x Number of training steps per epoch ."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3P-JYfZWQVh_",
        "outputId": "5ee9d0f2-4ce1-4724-a042-5f02d7017936"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:absl:using Adamw optimizer\n",
            "INFO:absl:gradient_clip_norm=1.000000\n"
          ]
        }
      ],
      "source": [
        "training_epochs = 3\n",
        "\n",
        "steps_per_epoch = 157\n",
        "num_train_steps = steps_per_epoch * training_epochs\n",
        "num_warmup_steps = int(0.1*num_train_steps)\n",
        "\n",
        "#init_lr = 3e-5\n",
        "#init_lr=2e-5\n",
        "#laut German bert docu:\n",
        "init_lr =1e-4 \n",
        "optimizer = optimization.create_optimizer(init_lr=init_lr,\n",
        "                                          num_train_steps=num_train_steps,\n",
        "                                          num_warmup_steps=num_warmup_steps,\n",
        "                                          optimizer_type='adamw')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "B-tWBjvUI_9x"
      },
      "outputs": [],
      "source": [
        "loss = tf.keras.losses.BinaryCrossentropy()\n",
        "metrics = tf.metrics.BinaryAccuracy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "D10-ZRr_QV6W"
      },
      "outputs": [],
      "source": [
        "model01203.compile(loss=loss, optimizer=optimizer ,metrics=[metrics,metrics_recall,metrics_precision,metrics_f1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cZWF9QIpOJga",
        "outputId": "5d448bf3-3c6c-4b42-bbd7-4c9453435b17"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2232: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ]
        }
      ],
      "source": [
        "# Encode training set X\n",
        "X_train_ids, X_train_attention, X_segments = tokenize(training_sentences,tokenizer)\n",
        "\n",
        "# Encode test set\n",
        "Y_test_ids, Y_test_attention, Y_segments = tokenize(testing_sentences,tokenizer)\n",
        "#encding von https://towardsdatascience.com/hugging-face-transformers-fine-tuning-distilbert-for-binary-classification-tasks-490f1d192379"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qQhkO9_5SGs4"
      },
      "source": [
        "steps-per-epoch-Erkl√§rung...\n",
        "https://stackoverflow.com/questions/49922252/choosing-number-of-steps-per-epoch\n",
        "Traditionally, the steps per epoch is calculated as train_length // batch_size, since this will use all of the data points, one batch size worth at a time."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "RzowLK8xgHzQ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pIOKqYkGerVJ",
        "outputId": "1a236301-d433-488e-d232-f52774ec777d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3\n",
            "157/157 [==============================] - 105s 546ms/step - loss: 0.6044 - binary_accuracy: 0.6858 - metrics_recall: 0.3144 - metrics_precision: 0.5114 - metrics_f1: 0.3363\n",
            "Epoch 2/3\n",
            "157/157 [==============================] - 88s 563ms/step - loss: 0.6422 - binary_accuracy: 0.6706 - metrics_recall: 0.0487 - metrics_precision: 0.1417 - metrics_f1: 0.0633\n",
            "Epoch 3/3\n",
            "157/157 [==============================] - 90s 570ms/step - loss: 0.6371 - binary_accuracy: 0.6678 - metrics_recall: 0.0244 - metrics_precision: 0.2208 - metrics_f1: 0.0435\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f8ed3cd2610>"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ],
      "source": [
        "model01203.fit(\n",
        "    x = [X_train_ids, X_train_attention, X_segments],\n",
        "    y=np.array(training_labels),\n",
        "    epochs = 3,\n",
        "    batch_size = 32\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rfW_WcDlWsZv"
      },
      "source": [
        "https://deeplizard.com/learn/video/km7pxKy4UHU\n",
        "\n",
        "Quelle der def plot_confusion_matrix: https://scikit-learn.org/stable/auto_examples/model_selection/plot_confusion_matrix.html#sphx-glr-auto-examples-model-selection-plot-confusion-matrix-py "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "6KWbgX5NLk9r"
      },
      "outputs": [],
      "source": [
        "BERTGermanPredict = model01203.predict([Y_test_ids, Y_test_attention, Y_segments])\n",
        "BERT_pred_thresh = np.where(BERTGermanPredict >= 0.5, 1, 0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "rk4KctG_MJ20",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f35dd873-a9ee-49d5-c9a8-5e5e65762914"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0],\n",
              "       [0],\n",
              "       [0],\n",
              "       ...,\n",
              "       [0],\n",
              "       [0],\n",
              "       [0]])"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ],
      "source": [
        "BERT_pred_thresh"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "kOwlJFGrMKeM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ba4f50ce-d82c-4fbb-8ea5-6caf0750c011"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.33915353],\n",
              "       [0.33912867],\n",
              "       [0.33916607],\n",
              "       ...,\n",
              "       [0.33917215],\n",
              "       [0.33912477],\n",
              "       [0.33912587]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ],
      "source": [
        "BERTGermanPredict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "TZjt-y0-WrPZ"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "import itertools\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "A5RUaFEcXmYc"
      },
      "outputs": [],
      "source": [
        "def plot_confusion_matrix(cm, classes,\n",
        "                        normalize=False,\n",
        "                        title='Confusion matrix',\n",
        "                        cmap=plt.cm.Blues):\n",
        "\n",
        "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
        "    plt.title(title)\n",
        "    plt.colorbar()\n",
        "    tick_marks = np.arange(len(classes))\n",
        "    plt.xticks(tick_marks, classes, rotation=45)\n",
        "    plt.yticks(tick_marks, classes)\n",
        "\n",
        "    if normalize:\n",
        "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
        "        print(\"Normalized confusion matrix\")\n",
        "    else:\n",
        "        print('Confusion matrix, without normalization')\n",
        "\n",
        "    print(cm)\n",
        "\n",
        "    thresh = cm.max() / 2.\n",
        "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
        "        plt.text(j, i, cm[i, j],\n",
        "            horizontalalignment=\"center\",\n",
        "            color=\"white\" if cm[i, j] > thresh else \"black\")\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.ylabel('True label')\n",
        "    plt.xlabel('Predicted label')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "4Mu7wle3Wr5S"
      },
      "outputs": [],
      "source": [
        "cm = confusion_matrix(y_true=testing_labels, y_pred=BERT_pred_thresh)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "QcIt6FU7Wr_q"
      },
      "outputs": [],
      "source": [
        "plot_labels = ['no hatespeech','hatespeech']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "X-K7cFJfWsGV",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "outputId": "c93a322d-3f62-4f9e-bb63-f0e69ae695a6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Confusion matrix, without normalization\n",
            "[[2308   22]\n",
            " [1175   27]]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWEAAAEmCAYAAACzoiEDAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3dd5xU1fnH8c93WUBQioQiFkARRWwICCr2jjFiBVFjjWisSYyxxJ+o0WhEY2KLLUaMimKL2FDUWEBRQLFgj6BUEQUEQerz++Ocweu6zM4uu9y5u8/b130xc247c5Fnzjz33HNkZjjnnEtHSdoVcM65usyDsHPOpciDsHPOpciDsHPOpciDsHPOpciDsHPOpciDsHNFQNLlkmZLmpl2XVZF0ouSfpV2PWobD8J1gKQjJb0u6TtJs+Lr0yQp7bpVVgwE30taIGmepJclbZ1Yf4mkpXF9bpmbWG/xOiyQNE3SXyXVk/R0YvulkpYk3t9Sw5+pHXAO0MXM1qvJc7ni40G4lpN0DvB3YDCwHtAGOBXoDTSowvFKq7WCVXOGma0DtABeBP5dZv0DZrZOYmleZv22cf/dgP7AiWbWJ7c9cC9wdWL/U2v487QDvjazWeWtLJJr7mqIB+FaTFIz4DLgNDN7yMzmW/CWmR1tZovjdg0lXSPpC0lfSrpFUqO4bndJUyWdF38q/yu2Nh+UdI+k+ZLelbSZpAtiS3uKpH0T9ThB0gdx288knZJYlzv+OXHfGZJOKOTzmdly4H6gS1Wuj5l9CowGulZl/6SyP9UlHS9pVOK9STpV0ieS5kq6ScHewEhg/djqvktSh7j9SZK+AF6IxzgxXsc5kp6R1D5x/M6SRkr6RtJHkvrF8txxc8tCSZbYL98x95H0YfzFcSOQuV9OWeBBuHbbEWgIPFbBdlcBmxGC0abABsDFifXrEVqd7YGBsewXhBbousBbwDOE/582IAT+WxP7zwIOBJoCJwDXSepW5vjN4r4nATdJWreiDyepAXA0MKaibVexf2dgF+DTquxfBQcC2wPbAP2A/czsOaAPMD22uo9PbL8bsAWwn6S+wIXAoUAr4BVgaPwcaxMC+X1Aa+BI4GZJXcxsevJXAfAo4YuLCo7ZEngEuAhoCfyP8OvJVTcz86WWLsAxwMwyZa8Cc4FFwK6E1s13QMfENjsCk+Lr3YElwFqJ9ZcAIxPvfwEsAOrF900AA5qvol7/Ac5OHH8RUJpYPwvYYRX7vggsjJ9hMTAP2KtM3ZbE9bnlv4n1BnwbP7MRgk7DMue4C7i8ktf6ReBXiffHA6PKnHfnxPthwPmJazA1sa5D3H6TRNnTwEmJ9yXxOrQnpFReKVOfW4FBZcrOA8YDjQo45rHAmMQ6AVOTn9GX6lm8JVy7fQ20TOYUzWwnCznSrwn/6FoBjYHx8WfyXGBELM/5ysy+L3PsLxOvFwGzLaQHcu8B1gGQ1EfSmPhTeS5wAKF1tbKeZrYs8X5hbt9VOCt+hkaE1uVDkrZJrB9mZs0Tyx5l9u8Wj98f6AWsnedc1SnZ86GizwgwJfG6PfD3xN/RN4TAuEFc1yu3Lq4/mvALAwh/B8DZwMFmtqiAY66fPL+FSJysj6smHoRrt9cIrcW+ebaZTQiaWyaCVjMLP11zqjzUnqSGwMPANUCbGDyfohryi2a2wsxeIaQT9q1o+zL7mpkNI1yjiyvavgDfEb7Mcqqjl0Pyuk8BTinz5dLIzF6N614qs24dM/s1gKTNgSFAPzObUuAxZwAb5TaUpOR7V308CNdiZjYXuJSQHzxcUhNJJZK6Elt/ZrYCuJ2Qp20NIGkDSftVUzUaEPLSXwHLYousUgEzH0k7Em7MTaziIa4CTpZUYdCMN8t2X8XqCcChkhpL2pSQ265OtwAXSNoy1qWZpCPiuieAzST9UlL9uGwvaQtJTQn3BP5oZqMqccwngS0lHRp/SZ1F9XyxuDI8CNdyZnY18DvgD4QUwpeEfOF5hPww8fWnwBhJ3wLPAZtX0/nnE/4BDwPmAEcBw1fzsDfm7vYTbg5eZGZPJ9b3L9MjYEHuC6ac+r0LvAycm++EkjYC5gPvrmKT6wi56C8Jrc57K/eR8jOzR4G/APfHv6P3CDf0ctd4X8INuemEtMdfCF9+3Qh/l9clr0cBx5wNHEH4kvoa6EToSeKqmUKqxzmXj6RjCCmbC9Kui6tdPAg751yKPB3hnHMp8iDsnHMp8iDsnHMp8oFBipRKG5kaNEm7GnXGdlu0S7sKdcrnn09m9uzZ1TIWRb2m7c2WLcq7jS366hkz2786zlfdPAgXKTVoQsPN+6VdjTpj9Os3pl2FOqV3rx7VdixbtqjCfyvfT7ipZd4NUuRB2DmXbRKU1Eu7FlXmQdg5l33K7u0tD8LOuYzzlrBzzqUrezN1reRB2DmXbcLTEc45lx5PRzjnXLo8HeGcc2mRpyOccy41wtMRzjmXHm8JO+dcegTU85awc86lx2/MOedcWjwd4Zxz6fIbc845lxLJ0xHOOZcqbwk751xaPCfsnHPp8nSEc86lRIKS7Iay7NbcOedyMtwSzm4ixTnnckrq5V8qIGkjSf+V9L6kiZLOjuUtJI2U9En8c91YLknXS/pU0juSuiWOdVzc/hNJx1VY9dX42M45lz7FG3P5lootA84xsy7ADsDpkroA5wPPm1kn4Pn4HqAP0CkuA4F/hKqoBTAI6AX0BAblAveqeBB2zmVfrq/wqpYKmNkMM3szvp4PfABsAPQFhsTNhgAHx9d9gbstGAM0l9QW2A8YaWbfmNkcYCSwf75ze07YOZdpAkpKKmxPtpQ0LvH+NjO7rdzjSR2A7YDXgTZmNiOumgm0ia83AKYkdpsay1ZVvkoehJ1z2aa45DfbzHpUeChpHeBh4Ddm9q0SrWgzM0m2GjUtl6cjnHMZJ6T8S0FHkeoTAvC9ZvZILP4yphmIf86K5dOAjRK7bxjLVlW+Sh6EnXOZV1JSknepiEKk/ifwgZn9NbFqOJDr4XAc8Fii/NjYS2IHYF5MWzwD7Ctp3XhDbt9YtkqejnDOZV6hrd08egO/BN6VNCGWXQhcBQyTdBLwOdAvrnsKOAD4FFgInABgZt9I+hMwNm53mZl9k+/EHoSdc5kmCZWsXhA2s1GsOrO8VznbG3D6Ko51J3Bnoef2IOycy7xqaAmnxoOwcy7zPAg751xaxGqnI9LkQdg5l3neEnbOuZQIFdQNrVh5EHbOZV92G8IehJ1zGSdPRzjnXKo8HeFqrQ3bNOeOPx1L6581wQzufHg0Nw19kYtP+zkH7rYNK8z46pv5DBx0DzO+mgfAtX84nP16b8nC75cwcNC/mfDhVACuOLsv+++yFSUSL7z+Iedc/VCaHy1TpkyZwq9OOJZZs75EEieeNJAzzjqbC847l6eefJwG9RuwcceO3HbHv2jevHna1V2jROHjQxSj7H59uDVi2fIVnP/XR+h22BXsduw1nNJ/Vzpvsh7XDXmenv2vZIcjr+LpV97jgoF9ANhv5y50bNeKrfpeyhmXD+X6C48EYIdtN2bHrpuwfb8/0/2IK+i+ZXt26d4pzY+WKaWlpVx19bW89c77vDRqDLfechMfvP8+e+29D+MnvMfYt96hU6fNGPyXK9Ou6poXu6jlW4qZB2GX18zZ365syS5YuJgPJ81k/VbNmf/d9yu3adyoIeEpTjhwt22474k3AHjj3ck0a9KI9Vo2xQwaNqhPg/qlNGxQSmlpPWZ98+2a/0AZ1bZtW7brFmbQadKkCZ07b8H06dPYe599KS0NP2h79tqBaVOnplnN1FTHKGpp8XSEK1i7ti3ouvmGjH1vMgCXnP4Ljj6wJ/MWLGL/gdcDsH7r5kydOWflPtO+nMv6rZvz+juTeHncJ0waeQVC3PLAy3w06cs0PkbmfT55MhMmvMX2PXv9qPzuu+7k8CP6p1SrdBV7oM2nKFvCku6SdHgltm8u6bSarNPqkDRZUsu067E61m7UgKHX/Ipzr3l4ZSv4kpsep1Of/+P+p8dxav9d8+6/yUYt2XzjNmy630V03O+P7N5zM3pv13FNVL1WWbBgAQP6Hcbga/9G06ZNV5b/5corqFdaypFHHZ1i7dLj6Yj0NQeKNghnXWlpCUOvOZkHnh7HYy+8/ZP1Dzw1loP36grA9Flz2XC9H+Y13KBNc6bPmkvfPbbljXcn892iJXy3aAnPjJ5Ir202XmOfoTZYunQpA/odRv8BR3PwIYeuLP/3kLt46sknuOvuezPdIqyqilIRxX5NaiQIS+og6QNJt8fpo5+V1Ciu6yppTJwm+tE8M5HuKulVSZ/lWsWS1pH0vKQ3Jb0rqW/c9iqgo6QJkgbHbc+VNDae59JYtrakJyW9Lek9Sf1j+WRJV8djviFp01jeStLD8ThjJfVOHOfOuO1buXpIqifpmnjsdySdmfg8Zybq3bl6r3jNumXQ0Xw0aSbX3/PCyrKO7VqtfH3g7tvw8eSQWnjypXc56sCeAPTcugPfLljEzNnfMmXmHHbpvin16pVQWlrCLt068eGkmWv2g2SYmXHqySexeectOPu3v1tZ/uwzI/jrtVfz0KPDady4cYo1TFeWg3BN5oQ7AQPM7GRJw4DDgHuAu4EzzewlSZcRpof+TTn7twV2BjoTRrF/CPgeOCTO/dQSGCNpOGEa6q3MrCuApH3j+XsSnqUZLmlXoBUw3cx+HrdrljjfPDPbWtKxwN+AA4G/A9eZ2ShJ7Qgj5G8B/BF4wcxOlNQceEPSc8CxQAegq5ktU5j+Ome2mXWLaZPfA78q+4ElDSRMnw311ynkGte4nbpuwtEH9uLdj6cx5v4w2/egG4dz/ME70al9a1asML6Y8Q1nXXE/ACNGTWS/nbdk4vBBLPx+Kadccg8Ajzz3Frttvxnjhl2IYYx89QOeevm91D5X1rw6ejT33ftvttpqa3p1D786Lr38z5zz27NYvHgxB+6/DxBuzt1w8y1pVjUVxZ5yyKcmg/AkM8uNUD8e6BCDXnMzeymWDwEeXMX+/zGzFcD7knIznAr4cwyoKwizmLYpZ9994/JWfL8OISi/Alwr6S/AE2b2SmKfoYk/r4uv9wa6JL5JmypMBLgvcJCk38fytYB2cftbzGwZhFH2E8fPzVk1HjiUcsTZX28DKGncutonFKyKVyd8RqPtzvhJ+TOj3l/lPr+9athPylasMM6MgdpVXu+dd2bR0p/+L7F/nwNSqE3xKfbWbj41GYQXJ14vBxqtxv65K3w0oTXb3cyWSppMCIBlCbjSzG79yQqpG2FaksslPW9ml8VVyf/Dc69LgB3M7PsyxxBwmJl9VKa8kM+zHO+V4ly1kaAkwy3hNXpjzszmAXMk7RKLfgm8lGeXspoBs2IA3gNoH8vnA00S2z0DnBhbrUjaQFJrSesDC83sHmAw0C2xT//En6/F188CK/O6kromjn9mDMZI2i6WjwROkVQay5PpCOdcjcj2jbk0WmTHAbdIagx8Rpwgr0D3Ao9LehcYB3wIYGZfSxot6T3gaTM7V9IWwGvxL2ABcAywKTBY0gpgKfDrxLHXlfQOocU6IJadBdwUy0uBl4FTgT8R8sbvSCoBJhFyyHcAm8XypcDtwI2V+HzOuSoo8jibl3JPOtVlMa3Rw8xmp12XnJLGra3h5v0q3tBVizlj/btyTerdqwfjx4+rltC5VtvNrMNxN+Td5qO/7D/ezHpUx/mqm+cmnXOZJrKdE/YgDJhZh7Tr4JyrOg/CzjmXFmU7J+xB2DmXacL7CTvnXIrk6QjnnEuTt4Sdcy4lWX9izoOwcy7zMtwQ9iDsnMs+T0c451xaMp6OqC0zazjn6qjQRS3/UuExwiQNs+L4M7mySyRNi5NFTJB0QGLdBZI+lfSRpP0S5fvHsk8lnV9I/T0IO+cyrlpGUbsL2L+c8uvMrGtcngKQ1AU4Etgy7nNznFWnHnAT0AfoAgyI2+bl6QjnXOatbjrCzF6W1KHAzfsC95vZYmCSpE8Js/gAfGpmnwFIuj9uu+oZEPCWsHMu6ypIRazmPbsz4nyRd+qH+TA3AKYktpkay1ZVnpcHYedcpoVR1EryLkBLSeMSy8ACDv0PoCPQFZgBXFsT9fd0hHMu8wpo7c6u7HjCZvblD8fX7cAT8e00YKPEphvGMvKUr5K3hJ1zmVcT0xtJapt4ewiQ6zkxHDhSUkNJGxMmEX4DGAt0krSxpAaEm3fDKzqPt4Sdc5kmrf4APpKGArsT0hZTgUHA7nFeSQMmA6cAmNlEScMIN9yWAaeb2fJ4nDMIc1DWA+40s4kVnduDsHMu81b3gTkzG1BO8T/zbH8FcEU55U8BT1Xm3KsMwpJu4MfTwJc92VmVOZFzztWUehl+Yi5fS3jcGquFc85VUeiGVguDsJkNSb6X1NjMFtZ8lZxzrnIy3BCuuHeEpB0lvQ98GN9vK+nmGq+Zc84VqKREeZdiVkgXtb8B+wFfA5jZ28CuNVkp55wrlABV8F8xK6h3hJlNKZNzWV4z1XHOuUqSau2NuZwpknYCTFJ94Gzgg5qtlnPOFS7D9+UKCsKnAn8nDEQxndAR+fSarJRzzhVKQEmGo3CFQdjMZgNHr4G6OOdclRT7zbd8CukdsYmkxyV9FUeef0zSJmuics45V5GKhrEs9kZyIb0j7gOGAW2B9YEHgaE1WSnnnKuMEinvUswKCcKNzezfZrYsLvcAa9V0xZxzrlBZDsL5xo5oEV8+HSesu58wlkR/KjlAhXPO1ZRwYy7tWlRdvhtz4wlBN/fxTkmsM+CCmqqUc84VrBqGskxTvrEjNl6TFXHOuaqqlQP4JEnaijCF88pcsJndXVOVcs65QtXmdAQAkgYRRpzvQsgF9wFGAR6EnXNFodhvvuVTSO+Iw4G9gJlmdgKwLdCsRmvlnHMFkmpp74iERWa2QtIySU2BWfx4RlHnnEtVrbwxlzBOUnPgdkKPiQXAazVaK+ecq4Qib+zmVcjYEafFl7dIGgE0NbN3arZazjlXGFH8KYd88j2s0S3fOjN7s2aq5ABatm3N4RedVvGGztV1qr3piGvzrDNgz2qui3POVUkhPQyKVb6HNfZYkxVxzrmqELV3ynvnnMuEDMdgD8LOuWwLYwZnNwp7EHbOZV69DCeFC5lZQ5KOkXRxfN9OUs+ar5pzzlUsN8dcVp+YK+T742ZgR2BAfD8fuKnGauScc5VUUsFSzApJR/Qys26S3gIwszmSGtRwvZxzriCSan3viKWS6hH6BiOpFbCiRmvlnHOVUOQZh7wKCcLXA48CrSVdQRhV7aIarZVzzhVIQGmGW8IVpkvM7F7gD8CVwAzgYDN7sKYr5pxzhVrdKe8l3SlplqT3EmUtJI2U9En8c91YLknXS/pU0jvJIR4kHRe3/0TScYXUvZDeEe2AhcDjwHDgu1jmnHPpU3hYI99SgLuA/cuUnQ88b2adgOfjewgTW3SKy0DgH7BycuRBQC+gJzAoF7jzKSQd8SQ/TPi5FrAx8BGwZQH7OudcjRJQbzWTwmb2sqQOZYr7EmYVAhgCvAicF8vvNjMDxkhqLqlt3HakmX0DIGkkIbAPzXfuQoay3Dr5Pja9fXgv51zRKKC121LSuMT728zstgr2aWNmM+LrmUCb+HoDYEpiu6mxbFXleVX6iTkze1NSr8ru55xzNaHAAXxmm1mPqp7DzEySVXX/fAqZ6PN3ibclQDdgek1UxjnnKq3Am29V8KWktmY2I6YbZsXyafx4ircNY9k0fkhf5MpfrOgkhTxM0iSxNCTkiPsWsJ9zzq0RNfTY8nAg18PhOOCxRPmxsZfEDsC8mLZ4BthX0rrxhty+sSyvvC3h+JBGEzP7fRU/hHPO1aiQjljNY0hDCa3YlpKmEno5XAUMk3QS8DnQL27+FHAA8Cmh59gJAGb2jaQ/AWPjdpflbtLlk296o1IzWyapd5U+lXPOrRGihNXuHTFgFav2KmdbA05fxXHuBO6szLnztYTfIOR/J0gaDjwIfJc42SOVOZFzztUEKdtDWRbSO2It4GvCnHK5/sIGeBB2zhWFYh+uMp98Qbh17BnxHj8E35wa6arhnHOVJWrvAD71gHWg3GSLB2HnXNGorUNZzjCzy9ZYTZxzrgpE8Q/cnk++IJzdrxbnXN1Riyf6/EnXDOecKzbVMYBPmlYZhAvpZOycc8UguyHYp7x3zmWeKKmlN+acc67o1eYbc845lwm19cacc84VP9XeJ+acc67oeTrCOedS5i1h55xLUYZjsAdh51y2hXREdqOwB2HnXMat1hRGqfMg7JzLvAzHYA/Czrlsk2rp2BHOARzTvS1br9eE+YuXcflznwGw3QZN+HmXVqzXpCFXvzCJL+Z+D8D2GzVl781artx3g2YNuer5z5g6bzG/2bU9zdYqZcnyMBT1DaM+Z8Hi5Wv+A2XUlClT+NUJxzJr1pdI4sSTBnLGWWdzzFH9+eSjjwCYO28uzZs15/XxE1Ku7ZqX4RjsQdjlN+bzebz0vzkc12P9lWUzvl3Mba9N5ahubX+07dgp3zJ2yrcArN+0IafsuBFT5y1euf5fb0xbGbBd5ZSWlnLV1deyXbduzJ8/n516dWevvffhnvseWLnNeeeeQ7NmzVKsZXrkN+ZcbfXp7IW0aFz/R2Uz5y+pcL8eGzVj/NR5NVWtOqdt27a0bRu+9Jo0aULnzlswffo0tujSBQAz4+GHhjHi2RfSrGYqau1Qls6tju4bNuWW16b8qOyXPdZnhcGEad/y9IezU6pZ9n0+eTITJrzF9j17rSwbPeoV2rRuw6adOqVYs/RkOAYXbxCW1AF4wsy2KnD7g4GPzez9mqxXVUg6HuhhZmekXZc1ocO6jViyfAUzvv1xKmLe98toWFrCwB02pFe7Zrz+hbeUK2vBggUM6HcYg6/9G02bNl1ZPuz+oRxx5IAUa5auLKcjsvzIdVkHA13SroSD7hs1ZVzMDefM+34ZAIuXrWDslHm0b9Eojapl2tKlSxnQ7zD6Dziagw85dGX5smXLeOw/j3D4Ef1TrF16hKin/EsxK/YgXE/S7ZImSnpWUiNJJ0saK+ltSQ9LaixpJ+AgYLCkCZI6xmWEpPGSXpHUGUDSEZLei/u/HMuOl/SYpBclfSJpUK4Cko6R9EY87q2S6sXyfSW9JulNSQ9KWieWby/p1Xj8NyQ1iYdaP9bnE0lXr9GruAaJkIoYl8gHlwjWblBv5eut1mvCjMQNO1cxM+PUk09i885bcPZvf/ejdS88/xybbd6ZDTfcMKXapUwhHZFvKWZFm46IOgEDzOxkScOAw4BHzOx2AEmXAyeZ2Q2ShhPSFw/Fdc8Dp5rZJ5J6ATcDewIXA/uZ2TRJzRPn6glsBSwExkp6EvgO6A/0NrOlkm4Gjpb0FHARsLeZfSfpPOB3kq4CHgD6m9lYSU2BRfH4XYHtgMXAR5JuMLMfJ02L0Ak9N2Czlo1Zp2EpV/TpxJMffMV3S5bTb9v1WKdhPU7r3Y6p877nxlFfALBpy8bMWbiUr79buvIYpSXizJ3bUa9ESPDRrO8YNWlOWh8pk14dPZr77v03W221Nb26dwXg0sv/zP59DuDBB+6nX/+6nIrwG3M1aZKZ5To9jgc6AFvF4NscWAd4puxOsVW6E/BgYrDnhvHP0cBdMag/kthtpJl9Hfd/BNgZWAZ0JwRlgEbALGAHQupjdCxvALwGbA7MMLOxAGb2bTwewPNmNi++fx9oD/woCEsaCAwEWKflj7t/peVfb0wrt/zt6fPLLf9k9kIGvzj5R2VLlhtXvTCpuqtWp/TeeWcWLbVy191+511rtjJFKLshuPiDcPI363JCELwLONjM3o43vHYvZ78SYK6ZdS27wsxOjS3jnwPjJXXPrSq7KeHvdoiZXZBcIekXhKA9oEz51pX4LD+59mZ2G3AbQOuOW5X/L84591MZjsLFnhMuTxNghqT6wNGJ8vlxXa4FOknSEQAKto2vO5rZ62Z2MfAVsFHcfx9JLSQ1ItzkGw08DxwuqXXct4Wk9sAYoLekTWP52pI2Az4C2kraPpY3kVTsX3TOZV6JlHcpZlkMwv8HvE4Ikh8myu8HzpX0lqSOhAB9kqS3gYlA37jdYEnvSnoPeBV4O5a/ATwMvAM8bGbjYne3i4BnJb0DjATamtlXwPHA0Fj+GtDZzJYQcsg3xPOOBNaqkavgnFtJFSzFrGhbaWY2mXCjLPf+msTqf5Sz/Wh+2kVt/3K2O7RsWczZTjWzg8vZ/gHCzbay5S8A25dTPpaQM066Ky65bQ4su59zrmpE9Uz0KWky4Rf1cmCZmfWQ1ILw778DMBnoZ2ZzFE74d+AAws38483szaqcN4stYeec+0H1dlHbw8y6mlmP+P58wk31ToT05PmxvA+h91Ynws30nzQMC+VBGDCzu+rK02zO1UY1mI7oCwyJr4cQ7hflyu+2YAzQXFKVujR5EHbOZZyQ8i9AS0njEsvAcg5khPs/4xPr25jZjPh6JtAmvt6AH3cxnRrLKq1oc8LOOVeoAlIOsxMphlXZOT7E1RoYKSl54x8zM0nV3nXUW8LOuUwLN+ZWPydsZtPin7OARwlP0X6ZSzPEP2fFzafxQ/dWgA1jWaV5EHbOZZ4q+K/C/UNf/ya518C+wHvAcOC4uNlxwGPx9XDg2PgMwg7AvETaolI8HeGcy7xq6KHWBng05o9LgfvMbISkscAwSScBnwP94vZPEbqnfUroonZCVU/sQdg5l23VMFKamX0GbFtO+dfAXuWUG3D66p018CDsnMu8LA/q7kHYOZdpIoxTnVUehJ1z2edB2Dnn0uPpCOecS5GnI5xzLk0ehJ1zLh1hkJ7sRmEPws65bJOnI5xzLl0ehJ1zLi3FP49cPh6EnXOZloV55PLxIOycy74MR2EPws65zPN0hHPOpSi7IdiDsHMu61Q9U96nxYOwcy7TctMbZZUHYedc5mU4BnsQds5ln9+Yc865NGU3BnsQds5lm3zsCOecS5ePouacc2nKbgz2IOycyz5PRzjnXGrk6QjnnEuLP6zhnHMp8yDsnHMp8nSEc86lxPsJO+dc2jwIO+dcejwd4ZxzKfJ0hHPOpcmDsHPOpUNkeyhLmecsQ68AAA7LSURBVFnadXDlkPQV8Hna9aiClsDstCtRh2T1erc3s1bVcSBJIwjXIZ/ZZrZ/dZyvunkQdtVK0jgz65F2PeoKv97ZV5J2BZxzri7zIOyccynyIOyq221pV6CO8eudcZ4Tds65FHlL2DnnUuRB2DnnUuRB2DnnUuRB2DnnUuRB2BUtSfXin+tJapR2fWobSSVl3mf32d8M8yDsio6kjSX1NrPlkn4BvAJcL+mKtOtWG0hqDGBmKyR1l3SYpLXMu0qlwruouaIjaQBwEzAQ2BN4DJgLnAl8bWZnp1i9TJPUHBgE/AdYAgwBpgOLgP8DJpjZsvRqWPd4S9gVHTMbCpwBXAc0MrNngPHA5UALSbemWb+MWxuYAfQHLgT6mtnuwFvAWUBXST664hrkQdgVjVxOUlInM7sP+A2wp6TdY+vsY+AqoLmkLilWNZMkycymAfcAHwCbAr0AzOxC4AvgfKBbapWsgzwIu6JhZibpIOB2SV3N7GHgEuAOSbuZ2QpC8DjRzN5Ps65ZEwOwSdob2BC4H7gd6C2pD4CZXQT8D1icXk3rHs8Ju6IRW7f/Bgaa2fhE+bHAYGCAmb2QVv2yLgbb64CzzewZSRsBfYEtgafM7PFUK1hHee7HFZNmwBe5ACypvpktNbO7JS0DvMVQRbFHxG+AX5vZf2PLeIqkx4GGwCGSxhAGP/frvAZ5EHapSfxELomphunA95K2AD4xs6WSdgW2M7O/J/dJs94ZVQ9oQLjGEALv98Ac4F9AUzP7KqW61WmeE3apSATgA4ErJF1L6DI1CzgdOFVSX0KAmJjbzwNwYRI3OdtLamhm84FngKskrWtm38cvuBEAZjY5vdrWbd4SdqmIAXgP4DLgSOBpQrrhD8CJQEdge+AMM3sutYpmVLy+BwB/BF6S1Bq4HmgKjJb0L+A44EIz+ybFqtZ5fmPOpUbSJcAoQvC9HDjKzCYl1jcys0UpVS/T4k3O+4CDCL8sugGHmdm3kvoTfnXMNrNXPMWTLm8JuzTNIDwV1xY4xswmSToBaGdml+JdpSotEVDXIgThTYHdgaNjAO4BPGJmS3P7eABOl+eE3RqRyFHuIGkvSd2BZ4FtgDuAz2PZ74DXIYxtkFZ9syYx+E6uYfUFcBThseT9zezT2Ef4AmDdFKroVsHTEW6NkbQfoZ/qYOCfQA+gHXASodXbBhhsZsP9J3LhEjc59wH6AW8CnwKtCOmIF4HJhKcNB5nZYylV1ZXD0xGuxsVWWgvgbOBgYCNCj4eZZvampP8SulA1MbPPPQBXTgzAewJ/I/QF/iNhLIhrCF3SfkNoGV9kZk/49S0u3hJ2a4yki4EFwOHA8Wb2saSjgHfN7N10a5ddcdzlM4A3gGXArcBBZjZVUmMzW5jY1gNwkfGWsKsRiZ/IbYD5MRC0ILTSWsWbRN2Ac4GT06xr1sVxl+cQxoJYDBxgZjPjWMwbSLojNzylB+Di40HY1YjEgxhXA29JWmZmx0nqCAyRNJlw1/4SMxuXYlUzJ/EFtx2wMeFG5jvAWGByDMA9CTngc3x84OLm6QhXIyRtSchFDiUEiFuAxmZ2QHwSrgSYYWZj/Cdy5cWbcDcTRpUz4CVC399NgN7AUuBqMxueWiVdQTwIu2on6WfA28C7hAcEFsbyJ4AHzWxImvXLuji2xt+B88zsrfil1h0Ya2aPS2oPLDKzWf4FV/y8n7CrFol+wB3M7GvgVKATsE9is9eBdVKoXuYl+gED7EEYfnJXgNjlbCFwbHz/uZnNiq89ABc5zwm71ZbIUR4EnCPpjNgVai3gb5K2B8YRxio4PdXKZlDi+u4FfE0Ycxmgp6TD4uD3LwE7SmpqZt+mVllXaR6E3WqLAWJH4FLC+A8fSGpmZg9JmgE8QOgb/Iu4zn8iV0LiC+5K4FwzmyDpYUIu+P/iuo7AXzwAZ48HYVddWhJau+vHJ+MOkLSc0P1sIOFBgvaEG0muEiS1BM4DDol9q7cBfgY8QnjIpTfwgM+MkU0ehF2VJH4ityT8RP4Y+JIwXOLVhCEqdwc6mdlTkloAV0oaZWYL0qp3RtUjDMC+v6TzCXn1XYHfE8aGWALsIekTMxuRXjVdVXjvCFdl8WfwCcBUQh/VJ4ClZjY/PohxD3CymY2O2zeJg4u7PBJfcNsSgu9XhN4PvwCetDA/XD9gTzM7VVI7YC9ghJnNSK/mrio8CLsqiUMi3g70Af4BiDBqlwHbEmbE+EPsMlViZis8F1w4hUk5rwbuIgx0v6OZfRbX7QHcSHgQY0Qsq2dmy1OqrlsNno5wBSkngLYhDEHZhTAe8AAzWxhbZV8BR5jZe3G/FeDdpQoRu6JtQHi8+yDCSHMzgAVxXVvgIkIf4RG5vxcPwNnlLWFXodjV7AAzeyT+RN4U+B/hgYF147qpkg4BDgTOTA4a4/KTVB8oNbNF8Vo3IIw49xlhYJ7j4g25voQxmBuZ2Tf+y6J28JawK8RSoJ2kj+Lrgwg3494F5gFdJHUgdFH7owfgwkkqBfYEvotPuu1MSD/sS5iSaF0zWyKpF3A+8JGZfQj+y6K28JawK0gcLOYx4Csz654o24XwBNdS4B7zAdkrLY4FfAWwHvB7M3tY0nqE2ZFfI/Q8+SVhsCMfkL2W8SDsVikZTONP5g0JjyP3IuR8v5K0kZlNyY1b6wG4cGWu712E63sd8JaZTZfUhDDd02zgAzN7wa9v7eNB2JUr0U3q58COwHIzGySpBPgr4YbRnwmPIZ9iZlNTrG7mJK7vhsA0oCEhFXEi8JSZ3SOpFVDfzKanWVdXs3wAH1euGCAOIATah4HjJD0ENDOz3xDGKjgPuNkDcOUlvuAeJFzjM4CXCeNC9JE0GPiQ8Li3q8W8JezKJakRoR/wNcD6wIWEqYkaEh6fnSupefzTfyJXkqSdCeMBH0JIOewAvEL4YusCbAd8bmbPp1ZJt0Z4EHYr5R6qSLxvBrQmtM72iF2o5gJPErpN+YwNlZB8oCJ2N/sY6ABcDgwijLHxBXCpmX2V2M+/5Gox76Lmcq3eZWa2VFJvwgMBk8xsvKTmhIcFNpK0NmHQmDs9ABcu97i2hbng9iAE3omE63oKcKKZvS3pcKA54YtvZRD2AFy7eRCu4xRmwTgXGB6D8RBCnvIOScfEcYE/Bf5EGK3rRDMb5a2zwkhqDDwp6XrCbCM3Ae8TbsJNJNz0nCapAbAFcJKZTUyrvm7N83REHRe7nl1NGKmrBHjUzJ6PT78NAQ40s5cldSHMEeeTclZSvJbnA98A58dW71GEFvH6hL7W/wOGmtmDqVXUpcKDcB2WGFinPmE8gj0IPSFui/nfQ4GHgIPNJ4xcLQoTcw4D/mxmg+OTcv2BzQkjpd3ijyLXTd5FrQ6LAbjEzJYSbg6NJIwLsb2kBmb2CNAPWJxmPWsDMxtJGPbzeEkDYk79fuAjwq+Pb+J2HoDrGG8J11FlntYqNbNlMS95MdAEGA68YmZLym7vqi72vf4TcL35rNMObwnXOXE4REj83ccAXD8G3MsIMzUcRmJmZA/A1cPMniIMdHSepPXjE4iuDvOWcB2SeFR2b8KAMJ8B/zOze+L6+rGbWgOgg5l9nGZ9azNJrZJ9gV3d5d/CdUgMwLsBNwAvEsYsOF3SOXH90pgjXuIBuGZ5AHY53k+47tkQuN3M/gUg6XVgsKQRZjYx+cScc67meUu4lkvkgHMaAcck3k8kzJLseSnnUuBBuJbLpSAknSapi5ndAbwu6XmFaeh7ANsA9dOtqXN1k9+Yq6USN+F6AXcSHpVdCIwC7iU8JdcB+BlwpT+M4Vw6PAjXYpJ6Erqc/cHM3pE0gDBk4jtm9s/YPaq5P6nlXHo8HVG7NQf2BvaJ7x8ERgM7SDobEDAHvB+wc2nx3hG1mJk9G8d/uFLSdDMbGmfHqAe8nRvb1jmXHg/CtZyF2Y+XAX+K40EMAYamXS/nXOA54TpC0kHAVYT0xEzvD+xccfAgXIf4o7LOFR8Pws45lyLvHeGccynyIOyccynyIOyccynyIOyccynyIOxSIWm5pAmS3pP0YJwavqrHukvS4fH1HXFm6FVtu7uknapwjsmSWhZaXmabBZU81yWSfl/ZOrps8iDs0rLIzLqa2VaE6ZROTa6MsxFXmpn9yszez7PJ7kClg7BzNcWDsCsGrwCbxlbqK5KGA+9LqidpsKSxkt6RdAqEEeIk3SjpI0nPAa1zB5L0oqQe8fX+kt6U9HYcurMDIdj/NrbCd5HUStLD8RxjJfWO+/5M0rOSJkq6gzDORl6S/iNpfNxnYJl118Xy5yW1imUdJY2I+7wiqXN1XEyXLf7YsktVbPH2AUbEom7AVmY2KQayeWa2vaSGwGhJzwLbAZsDXYA2hGE67yxz3FbA7cCu8Vgt4mhxtwALzOyauN19wHVmNkpSO+AZYAtgEDDKzC6T9HPgpAI+zonxHI2AsZIeNrOvgbWBcWb2W0kXx2OfAdwGnGpmn8QhR28G9qzCZXQZ5kHYpaWRpAnx9SvAPwlpgjfMbFIs3xfYJpfvBZoBnYBdgaFxAKLpkl4o5/g7AC/njmVm36yiHnsDXRITkDSVtE48x6Fx3yclzSngM50l6ZD4eqNY16+BFcADsfwe4JF4jp2ABxPnbljAOVwt40HYpWWRmXVNFsRg9F2yCDjTzJ4ps90B1ViPEmAHM/u+nLoUTNLuhIC+o5ktlPQisNYqNrd43rllr4Grezwn7IrZM8CvJdUHkLSZpLWBl4H+MWfcFtijnH3HALtK2jju2yKWzweaJLZ7Fjgz90ZSLii+DBwVy/oA61ZQ12bAnBiAOxNa4jklQK41fxQhzfEtMEnSEfEckrRtBedwtZAHYVfM7iDke9+U9B5wK+HX26PAJ3Hd3cBrZXeMAxUNJPz0f5sf0gGPA4fkbswBZwE94o2/9/mhl8alhCA+kZCW+KKCuo4ASiV9QBitbkxi3XdAz/gZ9iTMdgJwNHBSrN9EoG8B18TVMj6Aj3POpchbws45lyIPws45lyIPws45lyIPws45lyIPws45lyIPws45lyIPws45l6L/B3qr09NLB7fFAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "plot_confusion_matrix(cm=cm, classes=plot_labels, title='German BERT, unfreezed')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "gE5mZvfmUyJF"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import accuracy_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "-3NPPARgU0Kt"
      },
      "outputs": [],
      "source": [
        "accuracy = accuracy_score(testing_labels, BERT_pred_thresh)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "EUt-18pmU0pA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5cfd3f4a-d6a1-44f6-abf5-68001e5a6d7a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.6610985277463194"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ],
      "source": [
        "accuracy"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "03 huggingface German Bert ohne Freeze.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}