{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/BiancaStadl/Bachelorarbeit/blob/main/03_huggingface_German_Bert_ohne_Freeze.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BBsspqybXTK-"
      },
      "source": [
        "https://towardsdatascience.com/working-with-hugging-face-transformers-and-tf-2-0-89bf35e3555a\n",
        "\n",
        "\n",
        "Following is a general pipeline for any transformer model:\n",
        "Tokenizer definition ‚ÜíTokenization of Documents ‚ÜíModel Definition ‚ÜíModel Training ‚ÜíInference"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gYXyFyKAQjmg"
      },
      "source": [
        "https://colab.research.google.com/github/huggingface/notebooks/blob/master/transformers_doc/training.ipynb\n",
        "\n",
        "https://huggingface.co/transformers/ (get started)\n",
        "\n",
        "Sehr wichtig: https://huggingface.co/transformers/notebooks.html"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L7ifvIz0X2QH"
      },
      "source": [
        "Citation: Using GPU in colab and Tensorflow: https://colab.research.google.com/notebooks/gpu.ipynb#scrollTo=Y04m-jvKRDsJ"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NEx0JLGOX2my",
        "outputId": "ec579e06-4b1c-418d-fc68-745c8c677d63"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found GPU at: /device:GPU:0\n"
          ]
        }
      ],
      "source": [
        "%tensorflow_version 2.x\n",
        "import tensorflow as tf\n",
        "device_name = tf.test.gpu_device_name()\n",
        "if device_name != '/device:GPU:0':\n",
        "  raise SystemError('GPU device not found')\n",
        "print('Found GPU at: {}'.format(device_name))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vj0g2dfIX4K-",
        "outputId": "8ea24c8b-6372-441a-bfdb-ee8f422955fa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time (s) to convolve 32x7x7x3 filter over random 100x100x100x3 images (batch x height x width x channel). Sum of ten runs.\n",
            "CPU (s):\n",
            "2.8754645270000765\n",
            "GPU (s):\n",
            "0.03681936699990729\n",
            "GPU speedup over CPU: 78x\n"
          ]
        }
      ],
      "source": [
        "%tensorflow_version 2.x\n",
        "import tensorflow as tf\n",
        "import timeit\n",
        "\n",
        "device_name = tf.test.gpu_device_name()\n",
        "if device_name != '/device:GPU:0':\n",
        "  print(\n",
        "      '\\n\\nThis error most likely means that this notebook is not '\n",
        "      'configured to use a GPU.  Change this in Notebook Settings via the '\n",
        "      'command palette (cmd/ctrl-shift-P) or the Edit menu.\\n\\n')\n",
        "  raise SystemError('GPU device not found')\n",
        "\n",
        "def cpu():\n",
        "  with tf.device('/cpu:0'):\n",
        "    random_image_cpu = tf.random.normal((100, 100, 100, 3))\n",
        "    net_cpu = tf.keras.layers.Conv2D(32, 7)(random_image_cpu)\n",
        "    return tf.math.reduce_sum(net_cpu)\n",
        "\n",
        "def gpu():\n",
        "  with tf.device('/device:GPU:0'):\n",
        "    random_image_gpu = tf.random.normal((100, 100, 100, 3))\n",
        "    net_gpu = tf.keras.layers.Conv2D(32, 7)(random_image_gpu)\n",
        "    return tf.math.reduce_sum(net_gpu)\n",
        "  \n",
        "# We run each op once to warm up; see: https://stackoverflow.com/a/45067900\n",
        "cpu()\n",
        "gpu()\n",
        "\n",
        "# Run the op several times.\n",
        "print('Time (s) to convolve 32x7x7x3 filter over random 100x100x100x3 images '\n",
        "      '(batch x height x width x channel). Sum of ten runs.')\n",
        "print('CPU (s):')\n",
        "cpu_time = timeit.timeit('cpu()', number=10, setup=\"from __main__ import cpu\")\n",
        "print(cpu_time)\n",
        "print('GPU (s):')\n",
        "gpu_time = timeit.timeit('gpu()', number=10, setup=\"from __main__ import gpu\")\n",
        "print(gpu_time)\n",
        "print('GPU speedup over CPU: {}x'.format(int(cpu_time/gpu_time)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "p3xfitNdliBI"
      },
      "outputs": [],
      "source": [
        "\n",
        "import os\n",
        "import re\n",
        "import shutil\n",
        "import string\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from keras import losses\n",
        "from tensorflow import keras \n",
        "from keras import optimizers \n",
        "from keras import metrics \n",
        "\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import losses\n",
        "from tensorflow.keras import preprocessing\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "Bq08Me5la_Cc"
      },
      "outputs": [],
      "source": [
        "max_length = 60"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "InRwhH-dt7P9"
      },
      "source": [
        "Next step is now to perform tokenization on documents. It can be performed either by encode() or encode_plus() method.\n",
        "https://towardsdatascience.com/working-with-hugging-face-transformers-and-tf-2-0-89bf35e3555a\n",
        "\n",
        "https://huggingface.co/bert-base-german-cased\n",
        "\n",
        "mit folgenden Paramter (laut doku)\n",
        "\n",
        "batch_size = 1024\n",
        "n_steps = 810_000\n",
        "max_seq_len = 128 (and 512 later)\n",
        "learning_rate = 1e-4\n",
        "lr_schedule = LinearWarmup\n",
        "num_warmup_steps = 10_000\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "I3XyiQsHNl0z"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "def tokenize(sentences, tokenizer):\n",
        "    input_ids, input_masks, input_segments = [],[],[]\n",
        "    for sentence in sentences:\n",
        "        inputs = tokenizer.encode_plus(sentence, add_special_tokens=True, max_length=60, pad_to_max_length=True, truncation=True,\n",
        "                                             return_attention_mask=True, return_token_type_ids=True)\n",
        "        input_ids.append(inputs['input_ids'])\n",
        "        input_masks.append(inputs['attention_mask'])\n",
        "        input_segments.append(inputs['token_type_ids'])        \n",
        "        \n",
        "    return np.asarray(input_ids, dtype='int32'), np.asarray(input_masks, dtype='int32'), np.asarray(input_segments, dtype='int32')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3mud88oeQ9UL",
        "outputId": "d538b5b6-07ef-47ec-bec3-50daa91ba575"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.15.0)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.47)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.4.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.4.2)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.10.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.10.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.62.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (3.10.0.2)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.6)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.7.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.10.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.1.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_NYaByZROqzU",
        "outputId": "dd4e630b-2f24-47c2-f7c3-63583b8b72f6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "All model checkpoint layers were used when initializing TFBertForMaskedLM.\n",
            "\n",
            "All the layers of TFBertForMaskedLM were initialized from the model checkpoint at bert-base-german-cased.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertForMaskedLM for predictions without further training.\n"
          ]
        }
      ],
      "source": [
        "#2.3.3 Fine-tuning a Pretrained transformer model, noch immer von https://towardsdatascience.com/working-with-hugging-face-transformers-and-tf-2-0-89bf35e3555a\n",
        "\n",
        "from transformers import AutoTokenizer, TFAutoModelForMaskedLM, AutoConfig, AutoModelForMaskedLM\n",
        "german_bert='bert-base-german-cased'\n",
        "\n",
        "\n",
        "  # Defining German bert tokenizer\n",
        "tokenizer = AutoTokenizer.from_pretrained(german_bert, max_length=60, pad_to_max_length=True,add_special_tokens=True)\n",
        "#add_special_tokens: ->  <cls>, <sep>,<unk>, etc w.r.t Pretrained model in use. It should be always kept True\n",
        "\n",
        "#https://huggingface.co/transformers/model_doc/auto.html#autoconfig\n",
        "# Download configuration from huggingface.co and cache.\n",
        "config = AutoConfig.from_pretrained('bert-base-german-cased', dropout=0.2, attention_dropout=0.2, num_labels=2)\n",
        "\n",
        "config.output_hidden_states = False\n",
        "\n",
        "German_model20 = TFAutoModelForMaskedLM.from_pretrained(german_bert, config=config)\n",
        "\n",
        "input_ids_in = tf.keras.layers.Input(shape=(60,), name='input_token', dtype='int32')\n",
        "input_attmasks_in = tf.keras.layers.Input(shape=(60,), name='attention_token', dtype='int32') \n",
        "token_type_ids_in = tf.keras.layers.Input(shape=(60,),name=\"token_type_ids\", dtype='int32')\n",
        "\n",
        "embedding_layer = German_model20(input_ids=input_ids_in, attention_mask=input_attmasks_in, token_type_ids=token_type_ids_in)[0]\n",
        "X = tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(160, return_sequences=True, dropout=0.3))(embedding_layer)\n",
        "#X = tf.keras.layers.LSTM(100, return_sequences=True, dropout=0.3)(embedding_layer)\n",
        "X = tf.keras.layers.GlobalMaxPool1D()(X)\n",
        "X = tf.keras.layers.Dense(190, activation='relu')(X)\n",
        "X = tf.keras.layers.Dropout(0.2)(X)\n",
        "X = tf.keras.layers.Dense(1, activation='sigmoid')(X)\n",
        "model01202 = tf.keras.Model(inputs=[input_ids_in, input_attmasks_in,token_type_ids_in], outputs = X)\n",
        "\n",
        "\n",
        "# embedding_layer = German_model20(input_ids=input_ids_in, attention_mask=input_attmasks_in)[0]\n",
        "# #X = tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(100, return_sequences=True, dropout=0.1, recurrent_dropout=0.1))(embedding_layer)\n",
        "# X = tf.keras.layers.LSTM(100, return_sequences=True, dropout=0.3)(embedding_layer)\n",
        "# X = tf.keras.layers.GlobalMaxPool1D()(X)\n",
        "# X = tf.keras.layers.Dense(190, activation='relu')(X)\n",
        "# X = tf.keras.layers.Dropout(0.2)(X)\n",
        "# X = tf.keras.layers.Dense(1, activation='sigmoid')(X)\n",
        "# model01202 = tf.keras.Model(inputs=[input_ids_in, input_attmasks_in], outputs = X)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mC3Ce-wNQINj",
        "outputId": "acb3e38a-f2e6-4a03-aa58-de028e428361"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_token (InputLayer)       [(None, 60)]         0           []                               \n",
            "                                                                                                  \n",
            " attention_token (InputLayer)   [(None, 60)]         0           []                               \n",
            "                                                                                                  \n",
            " token_type_ids (InputLayer)    [(None, 60)]         0           []                               \n",
            "                                                                                                  \n",
            " tf_bert_for_masked_lm (TFBertF  TFMaskedLMOutput(lo  109112880  ['input_token[0][0]',            \n",
            " orMaskedLM)                    ss=None, logits=(No               'attention_token[0][0]',        \n",
            "                                ne, 60, 30000),                   'token_type_ids[0][0]']         \n",
            "                                 hidden_states=None                                               \n",
            "                                , attentions=None)                                                \n",
            "                                                                                                  \n",
            " bidirectional (Bidirectional)  (None, 60, 320)      38606080    ['tf_bert_for_masked_lm[0][0]']  \n",
            "                                                                                                  \n",
            " global_max_pooling1d (GlobalMa  (None, 320)         0           ['bidirectional[0][0]']          \n",
            " xPooling1D)                                                                                      \n",
            "                                                                                                  \n",
            " dense (Dense)                  (None, 190)          60990       ['global_max_pooling1d[0][0]']   \n",
            "                                                                                                  \n",
            " dropout_37 (Dropout)           (None, 190)          0           ['dense[0][0]']                  \n",
            "                                                                                                  \n",
            " dense_1 (Dense)                (None, 1)            191         ['dropout_37[0][0]']             \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 147,780,141\n",
            "Trainable params: 147,780,141\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model01202.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "G5qYC_xx_aTK"
      },
      "outputs": [],
      "source": [
        "import keras.backend as K\n",
        "\n",
        "def metrics_recall(data_true, data_pred):\n",
        "    true_positives = K.sum(K.round(K.clip(data_true*data_pred,0,1)))\n",
        "    possible_positives = K.sum(K.round(K.clip(data_true,0,1)))\n",
        "\n",
        "    recall = true_positives / (possible_positives+K.epsilon())\n",
        "    return recall\n",
        "\n",
        "\n",
        "def metrics_precision(data_true, data_pred):\n",
        "    true_positives = K.sum(K.round(K.clip(data_true*data_pred,0,1)))\n",
        "\n",
        "    positives_predicted = K.sum(K.round(K.clip(data_pred,0,1)))\n",
        "    precision = true_positives / (positives_predicted+K.epsilon())\n",
        "    return precision\n",
        "\n",
        "\n",
        "def metrics_f1(data_true, data_pred):\n",
        "    precision_data = metrics_precision(data_true, data_pred)\n",
        "    recall_data = metrics_recall(data_true, data_pred)\n",
        "    return 2*(precision_data*recall_data)/(precision_data+recall_data+K.epsilon())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "JVYBMvYSotTH"
      },
      "outputs": [],
      "source": [
        "url = \"https://github.com/uds-lsv/GermEval-2018-Data/archive/master.zip\"\n",
        "\n",
        "dataset = tf.keras.utils.get_file(\"GermEval-2018-Data-master.zip\", url, \n",
        "                                   extract=True, cache_dir='.',\n",
        "                                    cache_subdir='')\n",
        "\n",
        "dataset_dir = os.path.join(os.path.dirname(dataset), 'GermEval-2018-Data-master')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "cS14OUtfo34V"
      },
      "outputs": [],
      "source": [
        "#os.listdir(dataset_dir)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "2X429K6hpOVm"
      },
      "outputs": [],
      "source": [
        "training_file = os.path.join(dataset_dir, 'germeval2018.training.txt')\n",
        "#with open(training_file) as f:\n",
        " # print(f.read())\n",
        "\n",
        "#print()\n",
        "\n",
        "testing_file = os.path.join(dataset_dir, 'germeval2018.test.txt')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "iRqhP_Fx0cK3"
      },
      "outputs": [],
      "source": [
        "def remove_clutter(string):\n",
        "   string = re.sub(\"@[^\\s]+\",\" \",string)\n",
        "   string = re.sub(\"#[^\\s]+\",\" \", string)\n",
        "   string = re.sub(\"\\u00a9\",\" \", string)\n",
        "   string = re.sub(\"\\u00ae\",\" \", string)\n",
        "   string = re.sub(\"[\\u2000-\\u3300]\",\" \", string)\n",
        "   string = re.sub(\"\\ud83c[\\ud000-\\udfff]\",\" \", string)\n",
        "   string = re.sub(\"\\ud83d[\\ud000-\\udfff]\",\" \", string)\n",
        "   string = re.sub(\"\\ud83e[\\ud000-\\udfff]\",\" \", string)\n",
        "   string = re.sub(\"üòú\", \" \",string)\n",
        "   string = re.sub(\"üç´\", \" \",string)\n",
        "   string = re.sub(\"üòÅ\", \" \",string)\n",
        "   string = re.sub(\"üêñ\", \" \",string)\n",
        "   string = re.sub(\"üò°\", \" \",string)\n",
        "   string = re.sub(\"üòá\", \" \",string)\n",
        "   string = re.sub(\"üò¨\", \" \",string)\n",
        "   string = re.sub(\"üòÉ\", \" \",string)\n",
        "   string = re.sub(\"üòÇ\", \" \",string)\n",
        "   string = re.sub(\"üíô\", \" \",string)  \n",
        "   string = re.sub(\"üòõ\", \" \",string)\n",
        "   string = re.sub(\"üôè\", \" \",string)\n",
        "   string = re.sub(\"üëç\", \" \",string)\n",
        "   string = re.sub(\"üñï\", \" \",string)\n",
        "   string = re.sub(\"üòâ\", \" \",string)\n",
        "   string = re.sub(\"üí©\", \" \",string)\n",
        "   string = re.sub(\"ü§¢\", \" \",string)\n",
        "   string = re.sub(\"üëè\", \" \",string)\n",
        "   string = re.sub(\"üò®\", \" \",string)\n",
        "   string = re.sub(\"ü§£\", \" \",string)\n",
        "   string = re.sub(\"ü§°\", \" \",string)\n",
        "   string = re.sub(\"üòà\", \" \",string)\n",
        "   string = re.sub(\"üíÉüèΩ\", \" \",string)\n",
        "   string = re.sub(\"üëπ\", \" \",string)\n",
        "   string = re.sub(\"ü§ò\", \" \",string)\n",
        "   string = re.sub(\"üò±\", \" \",string)\n",
        "   string = re.sub(\"ü§î\", \" \",string) \n",
        "   string = re.sub(\"üåà\", \" \",string) \n",
        "   string = re.sub(\"üíï\", \" \",string) \n",
        "   string = re.sub(\"üë©‚Äç‚ù§Ô∏è‚Äçüë©\", \" \",string) \n",
        "   string = re.sub(\"üòç\", \" \",string) \n",
        "   string = re.sub(\"üëÜ\", \" \",string) \n",
        "   string = re.sub(\"üòñ\", \" \",string) \n",
        "   string = re.sub(\"üëá\", \" \",string) \n",
        "   string = re.sub(\"üî•\", \" \",string) \n",
        "   string = re.sub(\"üòò\", \" \",string) \n",
        "   string = re.sub(\"üéâ\", \" \",string) \n",
        "   string = re.sub(\"ü§¨\", \" \",string) \n",
        "   string = re.sub(\"üëä\", \" \",string)\n",
        "   string = re.sub(\"üá©üá™\", \" \",string)  \n",
        "   string = re.sub(\"üíî\", \" \",string)\n",
        "   string = re.sub(\"üôà\", \" \",string)\n",
        "   string = re.sub(\"ü§Ø\", \" \",string)\n",
        "   string = re.sub(\"üêü\", \" \",string)\n",
        "   string = re.sub(\"üõ∂\", \" \",string)\n",
        "   string = re.sub(\"üòä\", \" \",string)\n",
        "   string = re.sub(\"üòì\", \" \",string)\n",
        "   string = re.sub(\"üò≥\", \" \",string)\n",
        "   string = re.sub(\"üöÄ\", \" \",string)\n",
        "   string = re.sub(\"üëé\", \" \",string)\n",
        "   string = re.sub(\"üòé\", \" \",string)\n",
        "   string = re.sub(\"üê∏\", \" \",string)\n",
        "   string = re.sub(\"üìà\", \" \",string)\n",
        "   string = re.sub(\"üôÇ\", \" \",string)\n",
        "   string = re.sub(\"üòÖ\", \" \",string)\n",
        "   string = re.sub(\"üòÜ\", \" \",string)\n",
        "   string = re.sub(\"üôéüèø\", \" \",string)\n",
        "   string = re.sub(\"üëéüèΩ\", \" \",string)\n",
        "   string = re.sub(\"ü§≠\", \" \",string)\n",
        "   string = re.sub(\"üò§\", \" \",string)\n",
        "   string = re.sub(\"üòö\", \" \",string)\n",
        "   string = re.sub(\"üòä\", \" \",string)\n",
        "   string = re.sub(\"üò≤\", \" \",string)\n",
        "   string = re.sub(\"ü§Æ\", \" \",string)\n",
        "   string = re.sub(\"üôÑ\", \" \",string)\n",
        "   string = re.sub(\"ü§ë\", \" \",string)\n",
        "   string = re.sub(\"üéÖ\", \" \",string)\n",
        "   string = re.sub(\"üëã\", \" \",string)\n",
        "   string = re.sub(\"üí™\", \" \",string)\n",
        "   string = re.sub(\"üòÑ\", \" \",string)\n",
        "   string = re.sub(\"üßê\", \" \",string)\n",
        "   string = re.sub(\"üò†\", \" \",string)\n",
        "   string = re.sub(\"üéà\", \" \",string)\n",
        "   string = re.sub(\"üöÇ\", \" \",string)\n",
        "   string = re.sub(\"üòä\", \" \",string)\n",
        "   string = re.sub(\"üöá\", \" \",string)\n",
        "   string = re.sub(\"üöä\", \" \",string)\n",
        "   string = re.sub(\"ü§∑\", \" \",string)\n",
        "   string = re.sub(\"üò•\", \" \",string)\n",
        "   string = re.sub(\"üôÉ\", \" \",string)\n",
        "   string = re.sub(\"üî©\", \" \",string)\n",
        "   string = re.sub(\"üîß\", \" \",string)\n",
        "   string = re.sub(\"üî®\", \" \",string)\n",
        "   string = re.sub(\"üõ†\", \" \",string)\n",
        "   string = re.sub(\"üíì\", \" \",string)\n",
        "   string = re.sub(\"üí°\", \" \",string)\n",
        "   string = re.sub(\"üç∏\", \" \",string)\n",
        "   string = re.sub(\"ü•É\", \" \",string)\n",
        "   string = re.sub(\"ü•Ç\", \" \",string)\n",
        "   string = re.sub(\"üò∑\", \" \",string)\n",
        "   string = re.sub(\"ü§ê\", \" \",string)\n",
        "   string = re.sub(\"üåé\", \" \",string)\n",
        "   string = re.sub(\"üëë\", \" \",string)\n",
        "   string = re.sub(\"ü§õ\", \" \",string)\n",
        "   string = re.sub(\"üòÄ\", \" \",string)\n",
        "   string = re.sub(\"üõ§\", \" \",string)\n",
        "   string = re.sub(\"üéÑ\", \" \",string)\n",
        "   string = re.sub(\"üì¥\", \" \",string)\n",
        "   string = re.sub(\"üå≠\", \" \",string)\n",
        "   string = re.sub(\"ü§ï\", \" \",string)\n",
        "   string = re.sub(\"üò≠\", \" \",string)\n",
        "   string = re.sub(\"üçæ\", \" \",string)\n",
        "   string = re.sub(\"üçû\", \" \",string)\n",
        "   string = re.sub(\"ü§¶\", \" \",string)\n",
        "   string = re.sub(\"ü§Ø\", \" \",string)\n",
        "   string = re.sub(\"üïØÔ∏è\", \" \",string)\n",
        "\n",
        "   string = re.sub(\"OTHER|OFFENSE|ABUSE|INSULT\",\" \",string)\n",
        "   return string"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "5asMgo4LtnRg"
      },
      "outputs": [],
      "source": [
        "statementsForTraining = []\n",
        "sentimentsForTraining = []\n",
        "\n",
        "fileToRead = open(training_file, 'r')\n",
        "\n",
        "while True:\n",
        "  #next line in file\n",
        "  line = fileToRead.readline()\n",
        "\n",
        "  if line == \"\":\n",
        "   break\n",
        "\n",
        "  findSentiment = re.search(\"OTHER|OFFENSE\",line)\n",
        "\n",
        "  line = remove_clutter(line)\n",
        "      \n",
        "\n",
        "  statementsForTraining.append(line)\n",
        "\n",
        "  if findSentiment.group(0) == \"OTHER\":  \n",
        "    sentimentsForTraining.append(0)\n",
        "  else:\n",
        "    sentimentsForTraining.append(1)\n",
        "\n",
        "  if not line:\n",
        "    break\n",
        "\n",
        " #print(\"{}: {}\".format(count,line.strip()))\n",
        "  \n",
        " # print(sentiment.group(0))\n",
        " \n",
        "fileToRead.close()\n",
        "\n",
        "training_sentences = statementsForTraining\n",
        "training_labels = sentimentsForTraining\n",
        "\n",
        "#print(training_sentences[0:100])\n",
        "#print(training_labels[9])  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "VsqZPENb98gD"
      },
      "outputs": [],
      "source": [
        "\n",
        "statementsForTesting = []\n",
        "sentimentsForTesting = []\n",
        "\n",
        "fileToRead = open(testing_file, 'r')\n",
        "\n",
        "while True:\n",
        " \n",
        "  line = fileToRead.readline()\n",
        "\n",
        "  if line == \"\":\n",
        "   break\n",
        "\n",
        "  sent = re.search(\"OTHER|OFFENSE\",line)\n",
        "\n",
        "  line = remove_clutter(line)\n",
        "\n",
        "\n",
        "  statementsForTesting.append(line)\n",
        "  #print(len(line))\n",
        "\n",
        "  if sent.group(0) == \"OTHER\": \n",
        "    sentimentsForTesting.append(0)\n",
        "  else:\n",
        "    sentimentsForTesting.append(1)\n",
        "\n",
        "  if not line:\n",
        "    break\n",
        "\n",
        "\n",
        "fileToRead.close()\n",
        "\n",
        "\n",
        "testing_sentences = statementsForTesting\n",
        "testing_labels = sentimentsForTesting\n",
        "#print(len(testing_sentences))\n",
        "#print(testing_sentences)   \n",
        "#print(statementsForTesting)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "3XKTZ3dgItYe"
      },
      "outputs": [],
      "source": [
        "!pip install -q tf-models-official\n",
        "from official.nlp import optimization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vn7B2064ujon"
      },
      "source": [
        "[Linktext](https://stackoverflow.com/questions/38340311/what-is-the-difference-between-steps-and-epochs-in-tensorflow)\n",
        "What is train steps?\n",
        "Step: A training step means using one batch size of training data to train the model. Number of training steps per epoch: total_number_of_training_examples / batch_size . Total number of training steps: number_of_epochs x Number of training steps per epoch ."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3P-JYfZWQVh_",
        "outputId": "aa2dec27-9bba-4d24-8e7e-1617118c3363"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:absl:using Adamw optimizer\n",
            "INFO:absl:gradient_clip_norm=1.000000\n"
          ]
        }
      ],
      "source": [
        "training_epochs = 3\n",
        "\n",
        "steps_per_epoch = 157\n",
        "num_train_steps = steps_per_epoch * training_epochs\n",
        "num_warmup_steps = int(0.1*num_train_steps)\n",
        "\n",
        "#init_lr = 3e-5\n",
        "#init_lr=2e-5\n",
        "#laut German bert docu:\n",
        "init_lr =1e-4 \n",
        "optimizer = optimization.create_optimizer(init_lr=init_lr,\n",
        "                                          num_train_steps=num_train_steps,\n",
        "                                          num_warmup_steps=num_warmup_steps,\n",
        "                                          optimizer_type='adamw')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "B-tWBjvUI_9x"
      },
      "outputs": [],
      "source": [
        "loss = tf.keras.losses.BinaryCrossentropy()\n",
        "metrics = tf.metrics.BinaryAccuracy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "D10-ZRr_QV6W"
      },
      "outputs": [],
      "source": [
        "model01202.compile(loss=loss, optimizer=optimizer ,metrics=[metrics,metrics_recall,metrics_precision,metrics_f1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cZWF9QIpOJga",
        "outputId": "691d9dea-e9d6-4049-a177-457f9ebc98cf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2232: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ]
        }
      ],
      "source": [
        "# Encode training set X\n",
        "X_train_ids, X_train_attention, X_segments = tokenize(training_sentences,tokenizer)\n",
        "\n",
        "# Encode test set\n",
        "Y_test_ids, Y_test_attention, Y_segments = tokenize(testing_sentences,tokenizer)\n",
        "#encding von https://towardsdatascience.com/hugging-face-transformers-fine-tuning-distilbert-for-binary-classification-tasks-490f1d192379"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qQhkO9_5SGs4"
      },
      "source": [
        "steps-per-epoch-Erkl√§rung...\n",
        "https://stackoverflow.com/questions/49922252/choosing-number-of-steps-per-epoch\n",
        "Traditionally, the steps per epoch is calculated as train_length // batch_size, since this will use all of the data points, one batch size worth at a time."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "RzowLK8xgHzQ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pIOKqYkGerVJ",
        "outputId": "e960bf7b-549f-45b6-fc96-83955f109d94"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3\n",
            "157/157 [==============================] - 119s 635ms/step - loss: 0.5304 - binary_accuracy: 0.7343 - metrics_recall: 0.4850 - metrics_precision: 0.6312 - metrics_f1: 0.4994\n",
            "Epoch 2/3\n",
            "157/157 [==============================] - 103s 655ms/step - loss: 0.3886 - binary_accuracy: 0.8341 - metrics_recall: 0.7282 - metrics_precision: 0.7779 - metrics_f1: 0.7327\n",
            "Epoch 3/3\n",
            "157/157 [==============================] - 104s 664ms/step - loss: 0.2571 - binary_accuracy: 0.9056 - metrics_recall: 0.8518 - metrics_precision: 0.8660 - metrics_f1: 0.8501\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f4e70271a50>"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ],
      "source": [
        "model01202.fit(\n",
        "    x = [X_train_ids, X_train_attention, X_segments],\n",
        "    y=np.array(training_labels),\n",
        "    epochs = 3,\n",
        "    batch_size = 32\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rfW_WcDlWsZv"
      },
      "source": [
        "https://deeplizard.com/learn/video/km7pxKy4UHU\n",
        "\n",
        "Quelle der def plot_confusion_matrix: https://scikit-learn.org/stable/auto_examples/model_selection/plot_confusion_matrix.html#sphx-glr-auto-examples-model-selection-plot-confusion-matrix-py "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "6KWbgX5NLk9r"
      },
      "outputs": [],
      "source": [
        "BERTGermanPredict = model01202.predict([Y_test_ids, Y_test_attention, Y_segments])\n",
        "BERT_pred_thresh = np.where(BERTGermanPredict >= 0.5, 1, 0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "rk4KctG_MJ20",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0f746196-99f3-4624-c284-3545375447c6"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0],\n",
              "       [1],\n",
              "       [0],\n",
              "       ...,\n",
              "       [1],\n",
              "       [0],\n",
              "       [0]])"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ],
      "source": [
        "BERT_pred_thresh"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "kOwlJFGrMKeM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "43c0afaa-92d3-4fb2-9948-e550fb091b0d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.02578793],\n",
              "       [0.9119175 ],\n",
              "       [0.02718121],\n",
              "       ...,\n",
              "       [0.9605325 ],\n",
              "       [0.01658087],\n",
              "       [0.05164931]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ],
      "source": [
        "BERTGermanPredict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "TZjt-y0-WrPZ"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "import itertools\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "A5RUaFEcXmYc"
      },
      "outputs": [],
      "source": [
        "def plot_confusion_matrix(cm, classes,\n",
        "                        normalize=False,\n",
        "                        title='Confusion matrix',\n",
        "                        cmap=plt.cm.Blues):\n",
        "\n",
        "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
        "    plt.title(title)\n",
        "    plt.colorbar()\n",
        "    tick_marks = np.arange(len(classes))\n",
        "    plt.xticks(tick_marks, classes, rotation=45)\n",
        "    plt.yticks(tick_marks, classes)\n",
        "\n",
        "    if normalize:\n",
        "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
        "        print(\"Normalized confusion matrix\")\n",
        "    else:\n",
        "        print('Confusion matrix, without normalization')\n",
        "\n",
        "    print(cm)\n",
        "\n",
        "    thresh = cm.max() / 2.\n",
        "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
        "        plt.text(j, i, cm[i, j],\n",
        "            horizontalalignment=\"center\",\n",
        "            color=\"white\" if cm[i, j] > thresh else \"black\")\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.ylabel('True label')\n",
        "    plt.xlabel('Predicted label')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "4Mu7wle3Wr5S"
      },
      "outputs": [],
      "source": [
        "cm = confusion_matrix(y_true=testing_labels, y_pred=BERT_pred_thresh)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "QcIt6FU7Wr_q"
      },
      "outputs": [],
      "source": [
        "plot_labels = ['no hatespeech','hatespeech']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "X-K7cFJfWsGV",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "outputId": "db5c82e2-9050-4fda-98d9-9301515d813f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Confusion matrix, without normalization\n",
            "[[2110  220]\n",
            " [ 510  692]]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "plot_confusion_matrix(cm=cm, classes=plot_labels, title='German BERT, unfreezed')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "gE5mZvfmUyJF"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import accuracy_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "-3NPPARgU0Kt"
      },
      "outputs": [],
      "source": [
        "accuracy = accuracy_score(testing_labels, BERT_pred_thresh)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "EUt-18pmU0pA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8ec528f3-9d0d-4e48-ec57-d9ff85224037"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7933182332955833"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ],
      "source": [
        "accuracy"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "03 huggingface German Bert ohne Freeze.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}